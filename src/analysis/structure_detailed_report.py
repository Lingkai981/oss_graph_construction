"""
Actor-Actor å›¾ç»“æ„æŒ‡æ ‡è¯¦ç»†æŠ¥å‘Šç”Ÿæˆå™¨

å®šä½ç±»ä¼¼ detailed_report.pyï¼š
- è¯»å– full_analysis.jsonï¼ˆæ¥è‡ª actor_actor_structure_analyzer.py çš„è¾“å‡ºï¼‰
- å¯¹æ¯ä¸ªé¡¹ç›®è¾“å‡ºï¼šä¸¤é¡¹æŒ‡æ ‡çš„æ•°å€¼ã€å˜åŒ–ã€è§£é‡Šï¼Œä»¥åŠæœˆåº¦è¶‹åŠ¿è¡¨
- æ”¯æŒç­›é€‰ repo / top / min-threshold ç­‰
"""

import json
import argparse
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple


def _safe_float(x, default=None):
    try:
        if x is None:
            return default
        return float(x)
    except Exception:
        return default


def _safe_int(x, default=None):
    try:
        if x is None:
            return default
        return int(x)
    except Exception:
        return default


def _pct_change(old: Optional[float], new: Optional[float]) -> Optional[float]:
    if old is None or new is None:
        return None
    if abs(old) < 1e-12:
        return None
    return (new - old) / old * 100.0


def _fmt_num(x: Optional[float], nd: int = 4) -> str:
    if x is None:
        return "N/A"
    return f"{x:.{nd}f}"


def _fmt_int(x: Optional[int]) -> str:
    if x is None:
        return "N/A"
    return str(int(x))


def _pick_latest_metrics(metrics: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
    if not metrics:
        return None
    return sorted(metrics, key=lambda m: m.get("month", ""))[-1]


def _pick_earliest_metrics(metrics: List[Dict[str, Any]]) -> Optional[Dict[str, Any]]:
    if not metrics:
        return None
    return sorted(metrics, key=lambda m: m.get("month", ""))[0]


def _compute_repo_sort_key(
    metrics: List[Dict[str, Any]],
    sort_by: str
) -> float:
    """
    ç”¨äº --top æ’åºï¼šé»˜è®¤æŒ‰ latest çš„ longest_shortest_path é™åºï¼›
    ä½ ä¹Ÿå¯ä»¥ä¼  sort_by=avg_distance / lcc_node_count ç­‰ã€‚
    """
    last = _pick_latest_metrics(metrics)
    if not last:
        return -1.0

    v = last.get(sort_by)
    if v is None:
        return -1.0

    try:
        return float(v)
    except Exception:
        return -1.0


def generate_repo_report(repo_name: str, repo_data: Dict[str, Any]) -> str:
    """ç”Ÿæˆå•ä¸ªä»“åº“çš„ç»“æ„æŒ‡æ ‡è¯¦ç»†æŠ¥å‘Šï¼ˆé£æ ¼å¯¹é½ detailed_report.pyï¼‰"""
    lines: List[str] = []
    lines.append("=" * 80)
    lines.append(f"ğŸ§© é¡¹ç›®: {repo_name}")
    lines.append("=" * 80)

    metrics = repo_data.get("metrics", [])
    if len(metrics) < 1:
        lines.append("\nâš ï¸ æ²¡æœ‰ç»“æ„æŒ‡æ ‡æ•°æ®ï¼ˆå¯èƒ½è¯¥ repo æ²¡æœ‰ actor-actor å›¾æˆ–å›¾ä¸ºç©ºï¼‰")
        return "\n".join(lines)

    # æŒ‰æœˆä»½æ’åº
    sorted_metrics = sorted(metrics, key=lambda m: m.get("month", ""))
    earliest = sorted_metrics[0]
    latest = sorted_metrics[-1]

    # è¯»å…³é”®å­—æ®µ
    e_diam = _safe_int(earliest.get("longest_shortest_path"))
    l_diam = _safe_int(latest.get("longest_shortest_path"))

    e_avgd = _safe_float(earliest.get("average_distance"))
    l_avgd = _safe_float(latest.get("average_distance"))

    e_cc = _safe_int(earliest.get("connected_components_count"))
    l_cc = _safe_int(latest.get("connected_components_count"))

    e_lcc_n = _safe_int(earliest.get("lcc_node_count"))
    l_lcc_n = _safe_int(latest.get("lcc_node_count"))

    e_nodes = _safe_int(earliest.get("node_count"))
    l_nodes = _safe_int(latest.get("node_count"))

    e_edges = _safe_int(earliest.get("edge_count"))
    l_edges = _safe_int(latest.get("edge_count"))

    # å˜åŒ–
    diam_chg = None
    if e_diam is not None and l_diam is not None and e_diam != 0:
        diam_chg = (l_diam - e_diam) / e_diam * 100.0

    avgd_chg = _pct_change(e_avgd, l_avgd)

    period = f"{earliest.get('month', 'N/A')} â†’ {latest.get('month', 'N/A')}"
    lines.append(f"\nğŸ“… åˆ†æå‘¨æœŸ: {period} ({len(sorted_metrics)} ä¸ªæœˆ)")

    lines.append("\n" + "-" * 80)
    lines.append("ğŸ“Œ å›¾ç»“æ„æ¦‚è§ˆï¼ˆé»˜è®¤ï¼šæ— æƒã€æ— å‘ã€åˆå¹¶å¤šé‡è¾¹ï¼›åœ¨æœ€å¤§è¿é€šåˆ†é‡ LCC ä¸Šè®¡ç®—è·ç¦»æŒ‡æ ‡ï¼‰")
    lines.append("-" * 80)

    lines.append(f"   é¦–æœˆèŠ‚ç‚¹/è¾¹: {l_nodes if False else ''}")  # å ä½é¿å…ç¼–è¾‘å™¨æç¤ºï¼ˆä¸ä¼šå½±å“è¾“å‡ºï¼‰
    lines.pop()  # åˆ é™¤å ä½è¡Œ

    lines.append(f"   é¦–æœˆèŠ‚ç‚¹æ•°: {e_nodes}   è¾¹æ•°: {e_edges}   è¿é€šåˆ†é‡æ•°: {e_cc}   LCCèŠ‚ç‚¹æ•°: {e_lcc_n}")
    lines.append(f"   æœ«æœˆèŠ‚ç‚¹æ•°: {l_nodes}   è¾¹æ•°: {l_edges}   è¿é€šåˆ†é‡æ•°: {l_cc}   LCCèŠ‚ç‚¹æ•°: {l_lcc_n}")

    # æŒ‡æ ‡è§£é‡Šï¼ˆä»¿ detailed_report çš„â€œç»´åº¦è§£é‡Š + è®¡ç®—å£å¾„ + ç›´è§‰â€ï¼‰
    lines.append("\n" + "-" * 80)
    lines.append("ğŸ“ˆ æŒ‡æ ‡ 1ï¼šæœ€é•¿çš„æœ€çŸ­è·¯å¾„ï¼ˆLongest Shortest Pathï¼‰")
    lines.append("-" * 80)
    lines.append("   âœ… å£å¾„: åœ¨æœ€å¤§è¿é€šåˆ†é‡ï¼ˆLCCï¼‰ä¸Šè®¡ç®—ç›´å¾„ï¼ˆdiameterï¼‰")
    lines.append("   ğŸ’¡ ç›´è§‰: å€¼è¶Šå¤§ï¼Œè¡¨ç¤ºåä½œç½‘ç»œè¶Šâ€œæ‹‰é•¿â€ã€ä¿¡æ¯/åä½œè·¨è¶Šè¶Šå¤šè·³ï¼Œæ•´ä½“æ›´åˆ†æ•£")
    lines.append(f"   é¦–æœˆ: { _fmt_int(e_diam) }  â†’  æœ«æœˆ: { _fmt_int(l_diam) }")
    if diam_chg is None:
        lines.append("   å˜åŒ–ç‡: N/Aï¼ˆå¯èƒ½é¦–æœˆä¸º0/ç¼ºå¤±ï¼Œæˆ–æ•°æ®ä¸è¶³ï¼‰")
    else:
        lines.append(f"   å˜åŒ–ç‡: {diam_chg:+.1f}%")

    # ç®€å•æç¤º
    if e_diam is not None and l_diam is not None:
        if l_diam > e_diam:
            lines.append("   âš ï¸ æç¤º: ç›´å¾„å˜å¤§ï¼Œç½‘ç»œå¯èƒ½æ›´åˆ†æ•£/è·¨ç¾¤åä½œæˆæœ¬æ›´é«˜")
        elif l_diam < e_diam:
            lines.append("   âœ… æç¤º: ç›´å¾„å˜å°ï¼Œç½‘ç»œå¯èƒ½æ›´ç´§å‡‘/åä½œæ›´é›†ä¸­")
        else:
            lines.append("   â– æç¤º: ç›´å¾„ä¿æŒä¸å˜")

    lines.append("\n" + "-" * 80)
    lines.append("ğŸ“ˆ æŒ‡æ ‡ 2ï¼šæœ€çŸ­åˆ°å…¶ä»–èŠ‚ç‚¹çš„å¹³å‡è·ç¦»ï¼ˆAverage Distanceï¼‰")
    lines.append("-" * 80)
    lines.append("   âœ… å£å¾„: åœ¨æœ€å¤§è¿é€šåˆ†é‡ï¼ˆLCCï¼‰ä¸Šè®¡ç®—å¹³å‡æœ€çŸ­è·¯å¾„é•¿åº¦ï¼ˆaverage shortest path lengthï¼‰")
    lines.append("   ğŸ’¡ ç›´è§‰: å€¼è¶Šå¤§ï¼Œä»»æ„ä¸¤äººå¹³å‡éœ€è¦æ›´å¤šè·³æ‰èƒ½å…³è”ï¼Œç½‘ç»œæ›´ç–ï¼›è¶Šå°åˆ™æ›´ç´§å¯†")
    lines.append(f"   é¦–æœˆ: { _fmt_num(e_avgd, 4) }  â†’  æœ«æœˆ: { _fmt_num(l_avgd, 4) }")
    if avgd_chg is None:
        lines.append("   å˜åŒ–ç‡: N/Aï¼ˆå¯èƒ½é¦–æœˆä¸º0/ç¼ºå¤±ï¼Œæˆ–æ•°æ®ä¸è¶³ï¼‰")
    else:
        lines.append(f"   å˜åŒ–ç‡: {avgd_chg:+.1f}%")

    if e_avgd is not None and l_avgd is not None:
        if l_avgd > e_avgd:
            lines.append("   âš ï¸ æç¤º: å¹³å‡è·ç¦»ä¸Šå‡ï¼Œç½‘ç»œæ•´ä½“æ›´ç–ï¼Œåä½œè§¦è¾¾å¯èƒ½å˜æ…¢")
        elif l_avgd < e_avgd:
            lines.append("   âœ… æç¤º: å¹³å‡è·ç¦»ä¸‹é™ï¼Œç½‘ç»œæ›´ç´§å¯†ï¼Œåä½œè§¦è¾¾å¯èƒ½æ›´å¿«")
        else:
            lines.append("   â– æç¤º: å¹³å‡è·ç¦»ä¿æŒä¸å˜")

    # æœˆåº¦è¶‹åŠ¿è¡¨ï¼ˆå¯¹é½ detailed_report çš„â€œæœˆåº¦æŒ‡æ ‡è¶‹åŠ¿â€ï¼‰
    lines.append("\n" + "-" * 80)
    lines.append("ğŸ“… æœˆåº¦è¶‹åŠ¿ï¼ˆActor-Actor ç»“æ„æŒ‡æ ‡ï¼‰")
    lines.append("-" * 80)
    lines.append(f"   {'æœˆä»½':<10} {'èŠ‚ç‚¹':>6} {'è¾¹':>6} {'CC':>4} {'LCC_N':>6} {'ç›´å¾„':>6} {'å¹³å‡è·ç¦»':>10}")
    lines.append("   " + "-" * 60)

    for m in sorted_metrics:
        month = m.get("month", "N/A")
        nodes = _safe_int(m.get("node_count"), 0)
        edges = _safe_int(m.get("edge_count"), 0)
        cc = _safe_int(m.get("connected_components_count"), 0)
        lcc_n = _safe_int(m.get("lcc_node_count"), 0)
        diam = m.get("longest_shortest_path", None)
        avgd = m.get("average_distance", None)

        diam_s = _fmt_int(_safe_int(diam))
        avgd_s = _fmt_num(_safe_float(avgd), 4)

        lines.append(f"   {month:<10} {nodes:>6} {edges:>6} {cc:>4} {lcc_n:>6} {diam_s:>6} {avgd_s:>10}")

    # notesï¼ˆå¦‚æœè®¡ç®—å¤±è´¥/å›¾å¤ªå°ç­‰ï¼‰
    # æŠŠæ¯ä¸ªæœˆçš„ notes æ±‡æ€»ä¸€ä¸‹
    notes_counter: Dict[str, int] = {}
    for m in sorted_metrics:
        for note in (m.get("notes") or []):
            notes_counter[note] = notes_counter.get(note, 0) + 1
    if notes_counter:
        lines.append("\n" + "-" * 80)
        lines.append("ğŸ“ è®¡ç®—å¤‡æ³¨ï¼ˆnotes ç»Ÿè®¡ï¼‰")
        lines.append("-" * 80)
        for k, v in sorted(notes_counter.items(), key=lambda x: (-x[1], x[0])):
            lines.append(f"   - {k}: {v} æ¬¡")

    lines.append("")
    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(description="ç”Ÿæˆ Actor-Actor å›¾ç»“æ„æŒ‡æ ‡è¯¦ç»†æŠ¥å‘Š")
    parser.add_argument(
        "--input",
        type=str,
        default="output/actor-actor-structure/full_analysis.json",
        help="è¾“å…¥çš„å®Œæ•´ç»“æ„åˆ†ææ–‡ä»¶è·¯å¾„ï¼ˆfull_analysis.jsonï¼‰"
    )
    parser.add_argument(
        "--output",
        type=str,
        default="output/actor-actor-structure/structure_detailed_report.txt",
        help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆtxtï¼‰"
    )
    parser.add_argument(
        "--repo",
        type=str,
        default=None,
        help="åªåˆ†ææŒ‡å®šçš„ä»“åº“ï¼ˆå¯ç”¨é€—å·åˆ†éš”å¤šä¸ªï¼‰"
    )
    parser.add_argument(
        "--top",
        type=int,
        default=None,
        help="åªè¾“å‡ºæ’åºé å‰çš„å‰ N ä¸ªé¡¹ç›®ï¼ˆé»˜è®¤æŒ‰ latest longest_shortest_path æ’åºï¼‰"
    )
    parser.add_argument(
        "--sort-by",
        type=str,
        default="longest_shortest_path",
        help="--top çš„æ’åºå­—æ®µï¼ˆé»˜è®¤ longest_shortest_pathï¼Œå¯é€‰ average_distance / lcc_node_count ç­‰ï¼‰"
    )
    parser.add_argument(
        "--min-diameter",
        type=float,
        default=None,
        help="åªè¾“å‡º latest ç›´å¾„ >= è¯¥å€¼ çš„é¡¹ç›®"
    )
    parser.add_argument(
        "--min-avg-distance",
        type=float,
        default=None,
        help="åªè¾“å‡º latest å¹³å‡è·ç¦» >= è¯¥å€¼ çš„é¡¹ç›®"
    )

    args = parser.parse_args()

    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        return

    print(f"ğŸ“– è¯»å–ç»“æ„åˆ†ææ•°æ®: {input_path}")
    with open(input_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # data ç»“æ„ï¼š{repo_name: {"repo_name":..., "metrics":[...]}, ...}
    repos_to_analyze = list(data.keys())

    # repo ç­›é€‰
    if args.repo:
        specified_repos = [r.strip() for r in args.repo.split(",")]
        repos_to_analyze = [r for r in repos_to_analyze if r in specified_repos]
        if not repos_to_analyze:
            print(f"âŒ æœªæ‰¾åˆ°æŒ‡å®šçš„ä»“åº“: {args.repo}")
            return

    # ç»„è£… (repo, sort_key, latest_diam, latest_avgd)
    repos_ranked: List[Tuple[str, float, Optional[float], Optional[float]]] = []
    for repo in repos_to_analyze:
        metrics = (data.get(repo) or {}).get("metrics", [])
        last = _pick_latest_metrics(metrics)
        if not last:
            continue

        latest_diam = _safe_float(last.get("longest_shortest_path"))
        latest_avgd = _safe_float(last.get("average_distance"))

        # threshold ç­›é€‰
        if args.min_diameter is not None:
            if latest_diam is None or latest_diam < args.min_diameter:
                continue
        if args.min_avg_distance is not None:
            if latest_avgd is None or latest_avgd < args.min_avg_distance:
                continue

        key = _compute_repo_sort_key(metrics, args.sort_by)
        repos_ranked.append((repo, key, latest_diam, latest_avgd))

    if not repos_ranked:
        print("âŒ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„é¡¹ç›®")
        return

    # æ’åºï¼šsort_key é™åº
    repos_ranked.sort(key=lambda x: x[1], reverse=True)

    # top æˆªæ–­
    if args.top is not None:
        repos_ranked = repos_ranked[:args.top]

    print(f"ğŸ“Š å°†è¾“å‡º {len(repos_ranked)} ä¸ªé¡¹ç›®çš„è¯¦ç»†æŠ¥å‘Š")

    # ç”ŸæˆæŠ¥å‘Š
    reports: List[str] = []
    reports.append("=" * 80)
    reports.append("ğŸ” Actor-Actor å›¾ç»“æ„æŒ‡æ ‡è¯¦ç»†åˆ†ææŠ¥å‘Š")
    reports.append("=" * 80)
    reports.append(f"è¾“å…¥æ–‡ä»¶: {input_path}")
    reports.append(f"åˆ†æé¡¹ç›®æ•°: {len(repos_ranked)}")
    reports.append(f"æ’åºå­—æ®µ: latest {args.sort_by} (desc)")
    reports.append("")

    for repo, _key, _d, _a in repos_ranked:
        reports.append(generate_repo_report(repo, data[repo]))

    full_report = "\n".join(reports)

    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(full_report)

    print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {output_path}")

    # æ§åˆ¶å°é¢„è§ˆï¼š<=3 ä¸ªé¡¹ç›®æ—¶å…¨é‡æ‰“å°ï¼Œå¦åˆ™æ‰“å°å‰ 3 ä¸ª
    if len(repos_ranked) <= 3:
        print("\n" + full_report)
    else:
        print("\nğŸ“‹ å‰ 3 ä¸ªé¡¹ç›®é¢„è§ˆ:\n")
        for repo, _key, _d, _a in repos_ranked[:3]:
            print(generate_repo_report(repo, data[repo]))


if __name__ == "__main__":
    main()
