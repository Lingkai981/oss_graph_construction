"""
Newcomer / Core-evolution è¯¦ç»†æŠ¥å‘Šç”Ÿæˆå™¨ï¼ˆä¼˜åŒ–ç‰ˆï¼‰

åŸºäº newcomer_analyzer è¾“å‡ºç»“æ„ï¼ˆoutput/newcomer-analysis/full_analysis.jsonï¼‰ç”Ÿæˆé¢å‘é˜…è¯»è€…çš„å¯è§£é‡ŠæŠ¥å‘Šã€‚

æœ¬ç‰ˆæœ¬åœ¨åŸæœ‰åŸºç¡€ä¸Šæ–°å¢ï¼š
1) æ¯ä¸ªé¡¹ç›®æ˜¾ç¤ºâ€œæ€»å¾—åˆ†â€ï¼ˆå››ä¸ªä¸‰å±‚åˆ†æ total_score ä¹‹å’Œï¼‰
2) æ¯ä¸ªé¡¹ç›®æ˜¾ç¤ºâ€œé¢„è­¦ç­‰çº§â€ï¼ˆå‚è€ƒ README.md é£é™©ç­‰çº§åˆ’åˆ†é€»è¾‘ï¼‰
3) è‹¥å•é¡¹ä¸‰å±‚å¾—åˆ† > 15ï¼ˆä¸¥æ ¼å¤§äºï¼‰ï¼Œåˆ™å•ç‹¬ç»™å‡ºé—®é¢˜æ¥æºè¯´æ˜ï¼ˆå¯è§£é‡Šæç¤ºï¼‰

ç”¨æ³•ç¤ºä¾‹ï¼š
python -m src.analysis.newcomer_detailed_report_optimized --top 10
python -m src.analysis.newcomer_detailed_report_optimized --repo "kubernetes/kubernetes"
"""

import json
import argparse
from pathlib import Path
from typing import Dict, Any, List, Tuple
from datetime import datetime


# -----------------------------
# Format helpers
# -----------------------------
def _fmt(v: Any, default: str = "N/A", ndigits: int = 4) -> str:
    if v is None:
        return default
    if isinstance(v, int):
        return str(v)
    if isinstance(v, float):
        return f"{v:.{ndigits}f}"
    return str(v)


def _fmt_pct(v: Any, default: str = "N/A", ndigits: int = 2) -> str:
    if v is None:
        return default
    try:
        return f"{float(v) * 100:.{ndigits}f}%"
    except Exception:
        return default


# -----------------------------
# Scoring & warning level
# -----------------------------
_THREE_LAYER_KEYS = [
    "newcomer_distance",
    "periphery_to_core_monthly",
    "unreachable_to_all_core_rate",
    "unreachable_to_any_core_rate",
]


def compute_total_score(repo_data: Dict[str, Any]) -> float:
    """å››ä¸ªä¸‰å±‚åˆ†æ total_score ä¹‹å’Œï¼ˆç¼ºå¤±é¡¹æŒ‰ 0 è®¡ï¼‰ã€‚"""
    three = repo_data.get("three_layer_analysis", {}) or {}
    total = 0.0
    for k in _THREE_LAYER_KEYS:
        total += float((three.get(k, {}) or {}).get("total_score") or 0.0)
    return total


def warning_level(total_score: float) -> Tuple[str, str]:
    """å‚è€ƒ README.md çš„é£é™©ç­‰çº§åˆ’åˆ†é€»è¾‘ã€‚"""
    # README: â‰¥60 high, 40-59 medium, 20-39 low, <20 healthy
    if total_score >= 60:
        return "ğŸ”´", "high"
    if total_score >= 40:
        return "ğŸŸ ", "medium"
    if total_score >= 20:
        return "ğŸŸ¡", "low"
    return "ğŸŸ¢", "healthy"


def flagged_issues(repo_data: Dict[str, Any], threshold: float = 15.0) -> List[Tuple[str, float, str]]:
    """è¿”å›å•é¡¹ total_score > threshold çš„é—®é¢˜è¯´æ˜åˆ—è¡¨ï¼š[(key, score, message), ...]."""
    three = repo_data.get("three_layer_analysis", {}) or {}

    explanations = {
        "newcomer_distance": "æ–°äººå’Œæ ¸å¿ƒè´¡çŒ®è€…è”ç³»ä¸å¤Ÿç´§å¯†",
        "periphery_to_core_monthly": "æ–°äººéœ€è¦è¾ƒé•¿æ—¶é—´æ‰èƒ½æˆä¸ºæ ¸å¿ƒ",
        # å¯¹å¯è¾¾æ€§ä¸¤é¡¹ï¼Œç»™å‡ºåŒä¸€ç±»è§£é‡Šå¹¶æ ‡æ˜å£å¾„
        "unreachable_to_all_core_rate": "æ–°äººå’Œæ ¸å¿ƒè´¡çŒ®è€…ä¹‹é—´å¯è¾¾æ€§æ–­è£‚ï¼ˆä¸æ‰€æœ‰ core ä¸å¯è¾¾ï¼‰",
        "unreachable_to_any_core_rate": "æ–°äººå’Œæ ¸å¿ƒè´¡çŒ®è€…ä¹‹é—´å¯è¾¾æ€§æ–­è£‚ï¼ˆä¸è‡³å°‘ä¸€ä¸ª core ä¸å¯è¾¾ï¼‰",
    }

    out: List[Tuple[str, float, str]] = []
    for k in _THREE_LAYER_KEYS:
        score = float((three.get(k, {}) or {}).get("total_score") or 0.0)
        if score > threshold:
            out.append((k, score, explanations.get(k, k)))
    # æŒ‰ä¸¥é‡ç¨‹åº¦ä»é«˜åˆ°ä½
    out.sort(key=lambda x: x[1], reverse=True)
    return out


# -----------------------------
# Report blocks
# -----------------------------
def _fmt_score_block(name: str, three_layer: Dict[str, Any]) -> List[str]:
    lines: List[str] = []
    if not three_layer:
        lines.append(f"   âšª {name}: æ— ä¸‰å±‚åˆ†ææ•°æ®")
        return lines

    n_points = three_layer.get("n_points", 0)
    total = three_layer.get("total_score", 0.0)

    trend = three_layer.get("trend", {})
    recent = three_layer.get("recent", {})
    stability = three_layer.get("stability", {})

    lines.append(f"   ã€{name}ã€‘")
    lines.append(f"      æ•°æ®ç‚¹æ•°: {n_points}")
    lines.append(f"      ä¸‰å±‚æ€»åˆ†: {_fmt(total, ndigits=4)} / 25")
    lines.append(
        f"      ğŸ“‰ é•¿æœŸè¶‹åŠ¿: slope={_fmt(trend.get('slope'), ndigits=6)}  score={_fmt(trend.get('score'), ndigits=4)}"
    )
    lines.append(
        f"      ğŸ“… è¿‘æœŸçŠ¶æ€: early_avg={_fmt(recent.get('early_avg'))}  recent_avg={_fmt(recent.get('recent_avg'))}  "
        f"change={_fmt(recent.get('change'), ndigits=6)}  score={_fmt(recent.get('score'), ndigits=4)}"
    )
    lines.append(
        f"      ğŸ“Š ç¨³å®šæ€§: volatility={_fmt(stability.get('volatility'), ndigits=6)}  "
        f"threshold={_fmt(stability.get('threshold'), ndigits=3)}  score={_fmt(stability.get('score'), ndigits=4)}"
    )
    return lines


def _compute_health_score(repo_data: Dict[str, Any]) -> float:
    """è®¡ç®—å¥åº·åˆ† (100 - total_risk)"""
    three = repo_data.get("three_layer_analysis", {}) or {}
    risk_scores = [
        (three.get("newcomer_distance", {}) or {}).get("total_score", 0),
        (three.get("periphery_to_core_monthly", {}) or {}).get("total_score", 0),
        (three.get("unreachable_to_all_core_rate", {}) or {}).get("total_score", 0),
        (three.get("unreachable_to_any_core_rate", {}) or {}).get("total_score", 0),
    ]
    return max(0.0, 100.0 - sum(risk_scores))


def generate_summary_table(repos_ranked: List[Tuple[str, float]], all_data: Dict[str, Any]) -> str:
    """ç”Ÿæˆæ±‡æ€»æ’åè¡¨"""
    lines = []
    lines.append("-" * 90)
    lines.append("ğŸ† é¡¹ç›®æ–°äººå‹å¥½åº¦æ€»æ’å (åˆ†æ•°è¶Šé«˜è¶Šå¥½)")
    lines.append("-" * 90)
    lines.append(f"{'æ’å':<6} {'é¡¹ç›®åç§°':<40} {'å¥åº·åˆ†':>10}")
    lines.append("-" * 90)

    for idx, (repo, score) in enumerate(repos_ranked, 1):
        lines.append(f"{idx:<6} {repo:<40} {score:>10.2f}")

    lines.append("-" * 90)
    lines.append("")
    return "\n".join(lines)


def generate_repo_report(repo_name: str, repo_data: Dict[str, Any]) -> str:
    """ç”Ÿæˆå•ä¸ªé¡¹ç›®çš„è¯¦ç»†æŠ¥å‘Š"""
    # æå–æ•°æ®
    newcomer = repo_data.get("newcomer_distance", {}) or {}
    p2c = repo_data.get("periphery_to_core", {}) or {}
    reach = repo_data.get("core_reachability", {}) or {}
    three = repo_data.get("three_layer_analysis", {}) or {}

    reach_overall = reach.get("overall", {}) or {}

    # è®¡ç®—åˆ†æ•°
    health_score = _compute_health_score(repo_data)

    # é¢„è­¦ç­‰çº§
    warning_level = "low"
    if health_score < 60:
        warning_level = "high"
    elif health_score < 80:
        warning_level = "medium"

    level_icons = {
        "low": "ğŸŸ¢ ä¼˜ç§€ (Low Risk)",
        "medium": "ğŸŸ¡ è‰¯å¥½ (Medium Risk)",
        "high": "ğŸ”´ éœ€å…³æ³¨ (High Risk)"
    }

    lines = []
    lines.append("=" * 90)
    lines.append(f"ğŸ“Š é¡¹ç›®: {repo_name}")
    lines.append("=" * 90)
    lines.append(f"â­ æ–°äººå‹å¥½åº¦å¥åº·åˆ†: {health_score:.4f} / 100")
    lines.append(f"   ç­‰çº§: {level_icons.get(warning_level)}")

    # å¼‚å¸¸è¯´æ˜ (Risk > 10)
    abnormalities = []
    keys_map = {
        "newcomer_distance": "æ–°äººéœ€è¦è¾ƒé•¿æ—¶é—´æ‰èƒ½æˆä¸ºæ ¸å¿ƒ(è·ç¦»è¿œ)",
        "periphery_to_core_monthly": "æ–°äººæ™‹å‡æ ¸å¿ƒè€—æ—¶å˜é•¿",
        "unreachable_to_all_core_rate": "æ–°äººæ— æ³•æ¥è§¦ä»»ä½•æ ¸å¿ƒæˆå‘˜(å®Œå…¨æ–­è£‚)",
        "unreachable_to_any_core_rate": "æ–°äººéš¾ä»¥æ¥è§¦éƒ¨åˆ†æ ¸å¿ƒæˆå‘˜(éƒ¨åˆ†æ–­è£‚)"
    }

    for key, desc in keys_map.items():
        score = (three.get(key, {}) or {}).get("total_score", 0)
        if score > 10:
             abnormalities.append(f"   - {desc} (é£é™©æ‰£åˆ†: {score:.4f})")
             
    if abnormalities:
        lines.append(f"âš ï¸ ä¸»è¦é£é™©ç‚¹:")
        for a in abnormalities:
            lines.append(a)

    lines.append("")
    lines.append("ğŸ¯ æ ¸å¿ƒæŒ‡æ ‡æ¦‚è§ˆ")
    lines.append(f"   â‘  æ–°äººåˆ°æ ¸å¿ƒå¹³å‡æ­¥é•¿: {_fmt(newcomer.get('overall_avg_shortest_path_to_core'))}")
    lines.append(f"   â‘¡ æ™‹å‡æ ¸å¿ƒå¹³å‡è€—æ—¶: {_fmt(p2c.get('average_months_to_core'))} ä¸ªæœˆ")
    lines.append(f"   â‘¢ æ ¸å¿ƒæˆå‘˜ä¸å¯è¾¾æ¯”ä¾‹:")
    lines.append(f"      - ä¸æ‰€æœ‰ Core ä¸å¯è¾¾: {_fmt_pct(reach_overall.get('overall_unreachable_to_all_core_rate'))}")
    lines.append(f"      - ä¸ä»»ä¸€ Core ä¸å¯è¾¾: {_fmt_pct(reach_overall.get('overall_unreachable_to_any_core_rate'))}")

    # ---- ä¸‰å±‚åˆ†æ ----
    lines.append("\n" + "-" * 90)
    lines.append("ğŸ“ˆ ä¸‰å±‚åˆ†æè¯¦æƒ… (Trend / Recent / Stability) - æ‰£åˆ†åˆ¶(åˆ†æ•°è¶Šä½è¶Šå¥½)")
    lines.append("-" * 90)

    def _print_three(title, key):
        tdata = three.get(key, {}) or {}
        n = tdata.get("n_points", 0)
        total = tdata.get("total_score", 0.0)
        trend = tdata.get("trend", {})
        recent = tdata.get("recent", {})
        stability = tdata.get("stability", {})

        lines.append(f"   ã€{title}ã€‘")
        lines.append(f"      æ•°æ®ç‚¹æ•°: {n}")
        lines.append(f"      é£é™©æ‰£åˆ†: {total:.4f} / 25")

        # Trend
        slope = trend.get("slope", 0)
        t_score = trend.get("score", 0)
        icon = "ğŸ“‰" if slope > 0 else "ğŸ“ˆ"  # growth is bad here
        lines.append(f"      {icon} é•¿æœŸè¶‹åŠ¿: slope={slope:.6f}  score={t_score:.4f}")

        # Recent
        e_avg = recent.get("early_avg", 0)
        r_avg = recent.get("recent_avg", 0)
        change = recent.get("change", 0)
        r_score = recent.get("score", 0)
        lines.append(f"      ğŸ“… è¿‘æœŸçŠ¶æ€: early={e_avg:.4f}  recent={r_avg:.4f}  change={change:.6f}  score={r_score:.4f}")

        # Stability
        vol = stability.get("volatility", 0)
        s_score = stability.get("score", 0)
        lines.append(f"      ğŸ“Š ç¨³å®šæ€§: volatility={vol:.6f}  score={s_score:.4f}")

    _print_three("æ–°äººåˆ°æ ¸å¿ƒå¹³å‡æ­¥é•¿", "newcomer_distance")
    _print_three("æ™‹å‡æ ¸å¿ƒè€—æ—¶", "periphery_to_core_monthly")
    _print_three("ä¸æ‰€æœ‰ Core ä¸å¯è¾¾æ¯”ä¾‹", "unreachable_to_all_core_rate")
    _print_three("ä¸ä»»ä¸€ Core ä¸å¯è¾¾æ¯”ä¾‹", "unreachable_to_any_core_rate")

    lines.append("")
    lines.append("-" * 90)
    lines.append("ğŸ“… æœˆåº¦è¶‹åŠ¿è¡¨")
    lines.append("-" * 90)
    lines.append(f"   {'æœˆä»½':<16} {'æ–°äººæ•°':<10} {'æ–°äººæ­¥é•¿':<10} {'æ–°æ™‹æ ¸':<10} {'æ™‹æ ¸è€—æ—¶':<12} {'allä¸å¯è¾¾':<12} {'anyä¸å¯è¾¾':<12}")
    lines.append("   " + "-" * 86)

    # Merge monthly data
    # newcomer_distance.monthly_summary
    # periphery_to_core.monthly_summary
    # core_reachability.monthly_summary

    nm_map = {m["month"]: m for m in newcomer.get("monthly_summary", [])}
    pc_map = {m["month"]: m for m in p2c.get("monthly_summary", [])}
    cr_map = {m["month"]: m for m in reach.get("monthly_summary", [])}

    all_months = sorted(set(nm_map.keys()) | set(pc_map.keys()) | set(cr_map.keys()))

    for mon in all_months:
        nm = nm_map.get(mon, {})
        pc = pc_map.get(mon, {})
        cr = cr_map.get(mon, {})

        c0 = _fmt(nm.get("newcomers", 0))
        c1 = _fmt(nm.get("avg_shortest_path_to_core"), "N/A")
        c2 = _fmt(pc.get("new_core_count", 0))
        c3 = _fmt(pc.get("avg_months_to_core"), "N/A")
        c4 = _fmt_pct(cr.get("unreachable_to_all_core_rate"), "N/A")
        c5 = _fmt_pct(cr.get("unreachable_to_any_core_rate"), "N/A")

        lines.append(f"   {mon:<16} {c0:<10} {c1:<10} {c2:<10} {c3:<12} {c4:<12} {c5:<12}")

    lines.append("")
    return "\n".join(lines)


def main():
    parser = argparse.ArgumentParser(description="Newcomer / Core-evolution è¯¦ç»†æŠ¥å‘Šç”Ÿæˆå™¨")
    parser.add_argument(
        "--input",
        type=str,
        default="output/newcomer-analysis/full_analysis.json",
        help="è¾“å…¥åˆ†ææ–‡ä»¶è·¯å¾„",
    )
    parser.add_argument(
        "--output",
        type=str,
        default="output/newcomer-analysis/detailed_report.txt",
        help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„",
    )
    parser.add_argument(
        "--repo",
        type=str,
        default=None,
        help="åªåˆ†ææŒ‡å®šçš„ä»“åº“",
    )
    parser.add_argument(
        "--top",
        type=int,
        default=None,
        help="åªè¾“å‡ºå‰ N ä¸ªé¡¹ç›®",
    )

    args = parser.parse_args()

    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        return

    print(f"ğŸ“– è¯»å–åˆ†ææ•°æ®: {input_path}")
    with open(input_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    repos_to_analyze = list(data.keys())

    if args.repo:
        specified = [r.strip() for r in args.repo.split(",") if r.strip()]
        repos_to_analyze = [r for r in repos_to_analyze if r in specified]

    # è®¡ç®—åˆ†æ•°å¹¶æ’åº
    repos_ranked: List[Tuple[str, float]] = []
    for repo in repos_to_analyze:
        score = _compute_health_score(data[repo])
        repos_ranked.append((repo, score))

    # ä»å¤§åˆ°å°æ’åº (è¶Šå¤§çº¦å¥½)
    repos_ranked.sort(key=lambda x: x[1], reverse=True)

    if args.top is not None:
        repos_ranked = repos_ranked[: args.top]

    if not repos_ranked:
        print("âŒ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„é¡¹ç›®")
        return

    # ç”ŸæˆæŠ¥å‘Š
    reports: List[str] = []
    reports.append("=" * 90)
    reports.append("ğŸ” OSS é¡¹ç›®æ–°äººä½“éªŒä¸æ ¸å¿ƒæ™‹å‡åˆ†ææŠ¥å‘Š")
    reports.append("=" * 90)
    reports.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    reports.append(f"åˆ†æé¡¹ç›®æ•°: {len(repos_ranked)}")
    reports.append("")

    # 1. æ’å…¥æ€»è§ˆè¡¨
    reports.append(generate_summary_table(repos_ranked, data))

    # 2. è¯¦ç»†æŠ¥å‘Š
    for repo, _ in repos_ranked:
        reports.append(generate_repo_report(repo, data[repo]))

    full_report = "\n".join(reports)

    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(full_report)

    print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {output_path}")

    # æ§åˆ¶å°é¢„è§ˆ
    if len(repos_ranked) <= 3:
        print("\n" + full_report)
    else:
        print("\nğŸ“‹ å‰ 3 ä¸ªé¡¹ç›®é¢„è§ˆ:\n")
        for repo, _ in repos_ranked[:3]:
            print(generate_repo_report(repo, data[repo]))


if __name__ == "__main__":
    main()
