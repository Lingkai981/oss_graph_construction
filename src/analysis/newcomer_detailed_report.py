"""
Newcomer / Core-evolution è¯¦ç»†æŠ¥å‘Šç”Ÿæˆå™¨

é€‚é… newcomer_analyzer_v3 çš„è¾“å‡ºç»“æ„ï¼ˆoutput/newcomer-analysis/full_analysis.jsonï¼‰ã€‚

è¾“å‡ºå†…å®¹ï¼ˆæŒ‰é¡¹ç›®ï¼‰ï¼š
- æŒ‡æ ‡1ï¼šæ–°äººåŠ å…¥æ—¶åˆ°å½“æœˆæ ¸å¿ƒæˆå‘˜çš„å¹³å‡æœ€çŸ­è·¯å¾„ï¼ˆoverall + æœˆåº¦è¶‹åŠ¿ï¼‰
- æŒ‡æ ‡2ï¼šæ ¸å¿ƒæˆå‘˜ä»é¦–æ¬¡å‡ºç°åˆ°é¦–æ¬¡æˆä¸º core çš„è€—æ—¶ï¼ˆoverall + â€œæ¯æœˆæ–°æ™‹æ ¸å¿ƒâ€æœˆåº¦è¶‹åŠ¿ï¼‰
- æŒ‡æ ‡3ï¼šéæ ¸å¿ƒæˆå‘˜ä¸æ ¸å¿ƒæˆå‘˜ä¸å¯è¾¾ç»Ÿè®¡ï¼ˆoverall + æœˆåº¦è¶‹åŠ¿ï¼›åŒºåˆ† any/allï¼‰
- ä¸‰å±‚åˆ†æï¼šå¯¹ä¸‰ä¸ªæŒ‡æ ‡çš„æœˆåº¦åºåˆ—åšé•¿æœŸè¶‹åŠ¿/è¿‘æœŸçŠ¶æ€/ç¨³å®šæ€§åˆ†æï¼ˆè‹¥å­˜åœ¨ï¼‰

ç”¨æ³•ç¤ºä¾‹ï¼š
python -m src.analysis.newcomer_detailed_report --top 10
python -m src.analysis.newcomer_detailed_report --repo "kubernetes/kubernetes"
"""

import json
import argparse
from pathlib import Path
from typing import Dict, Any, List, Tuple, Optional
from datetime import datetime


def _fmt(v: Any, default: str = "N/A", ndigits: int = 4) -> str:
    if v is None:
        return default
    if isinstance(v, (int,)):
        return str(v)
    if isinstance(v, float):
        return f"{v:.{ndigits}f}"
    return str(v)


def _fmt_pct(v: Any, default: str = "N/A", ndigits: int = 2) -> str:
    if v is None:
        return default
    try:
        return f"{float(v) * 100:.{ndigits}f}%"
    except Exception:
        return default


def _fmt_score_block(name: str, three_layer: Dict[str, Any]) -> List[str]:
    lines: List[str] = []
    if not three_layer:
        lines.append(f"   âšª {name}: æ— ä¸‰å±‚åˆ†ææ•°æ®")
        return lines

    n_points = three_layer.get("n_points", 0)
    total = three_layer.get("total_score", 0.0)

    trend = three_layer.get("trend", {})
    recent = three_layer.get("recent", {})
    stability = three_layer.get("stability", {})

    lines.append(f"   ã€{name}ã€‘")
    lines.append(f"      æ•°æ®ç‚¹æ•°: {n_points}")
    lines.append(f"      ä¸‰å±‚æ€»åˆ†: {_fmt(total, ndigits=4)} / 25")
    lines.append(f"      ğŸ“‰ é•¿æœŸè¶‹åŠ¿: slope={_fmt(trend.get('slope'), ndigits=6)}  score={_fmt(trend.get('score'), ndigits=4)}")
    lines.append(
        f"      ğŸ“… è¿‘æœŸçŠ¶æ€: early_avg={_fmt(recent.get('early_avg'))}  recent_avg={_fmt(recent.get('recent_avg'))}  "
        f"change={_fmt(recent.get('change'), ndigits=6)}  score={_fmt(recent.get('score'), ndigits=4)}"
    )
    lines.append(
        f"      ğŸ“Š ç¨³å®šæ€§: volatility={_fmt(stability.get('volatility'), ndigits=6)}  "
        f"threshold={_fmt(stability.get('threshold'), ndigits=3)}  score={_fmt(stability.get('score'), ndigits=4)}"
    )
    return lines


def generate_repo_report(repo_name: str, repo_data: Dict[str, Any]) -> str:
    lines: List[str] = []
    lines.append("=" * 90)
    lines.append(f"ğŸ“Š é¡¹ç›®: {repo_name}")
    lines.append("=" * 90)

    newcomer = repo_data.get("newcomer_distance", {})
    p2c = repo_data.get("periphery_to_core", {})
    reach = repo_data.get("core_reachability", {})
    three = repo_data.get("three_layer_analysis", {})

    # ---- æ¦‚è§ˆ ----
    overall_dist = newcomer.get("overall_avg_shortest_path_to_core")
    avg_months_to_core = p2c.get("average_months_to_core")
    reach_overall = reach.get("overall", {}) or {}
    unreach_all_rate = reach_overall.get("overall_unreachable_to_all_core_rate")
    unreach_any_rate = reach_overall.get("overall_unreachable_to_any_core_rate")

    lines.append("\nğŸ¯ æŒ‡æ ‡æ¦‚è§ˆï¼ˆé¡¹ç›®çº§ï¼‰")
    lines.append(f"   â‘  æ–°äººåˆ°æ ¸å¿ƒå¹³å‡æ­¥é•¿ï¼ˆoverallï¼‰: {_fmt(overall_dist)}")
    lines.append(f"   â‘¡ Peripheryâ†’Core å¹³å‡è€—æ—¶ï¼ˆæœˆï¼‰ï¼ˆoverallï¼‰: {_fmt(avg_months_to_core)}")
    lines.append(f"   â‘¢ ä¸å¯è¾¾æ¯”ä¾‹ï¼ˆoverallï¼‰:")
    lines.append(f"      - ä¸æ‰€æœ‰ core ä¸å¯è¾¾: {_fmt_pct(unreach_all_rate)}")
    lines.append(f"      - ä¸è‡³å°‘ä¸€ä¸ª core ä¸å¯è¾¾: {_fmt_pct(unreach_any_rate)}")

    # ---- ä¸‰å±‚åˆ†æ ----
    lines.append("\n" + "-" * 90)
    lines.append("ğŸ“ˆ ä¸‰å±‚åˆ†æï¼ˆé•¿æœŸè¶‹åŠ¿ / è¿‘æœŸçŠ¶æ€ / ç¨³å®šæ€§ï¼‰")
    lines.append("-" * 90)

    lines.extend(_fmt_score_block("æ–°äººåˆ°æ ¸å¿ƒå¹³å‡æ­¥é•¿", three.get("newcomer_distance", {})))
    lines.extend(_fmt_score_block("æ¯æœˆæ–°æ™‹æ ¸å¿ƒçš„ Peripheryâ†’Core è€—æ—¶", three.get("periphery_to_core_monthly", {})))
    lines.extend(_fmt_score_block("ä¸æ‰€æœ‰ core ä¸å¯è¾¾æ¯”ä¾‹", three.get("unreachable_to_all_core_rate", {})))
    lines.extend(_fmt_score_block("ä¸è‡³å°‘ä¸€ä¸ª core ä¸å¯è¾¾æ¯”ä¾‹", three.get("unreachable_to_any_core_rate", {})))

    # ---- æœˆåº¦è¶‹åŠ¿è¡¨ ----
    lines.append("\n" + "-" * 90)
    lines.append("ğŸ“… æœˆåº¦è¶‹åŠ¿ï¼ˆæ¥è‡ª newcomer_analyzer è¾“å‡ºçš„ monthly_summaryï¼‰")
    lines.append("-" * 90)

    newcomer_monthly = newcomer.get("monthly_summary", []) or []
    p2c_monthly = p2c.get("monthly_summary", []) or []
    reach_monthly = reach.get("monthly_summary", []) or []

    # å»ºç´¢å¼•ï¼ˆæŒ‰ monthï¼‰
    def _index_by_month(items: List[Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
        out: Dict[str, Dict[str, Any]] = {}
        for it in items:
            m = it.get("month")
            if m:
                out[m] = it
        return out

    idx_new = _index_by_month(newcomer_monthly)
    idx_p2c = _index_by_month(p2c_monthly)
    idx_rch = _index_by_month(reach_monthly)

    all_months = sorted(set(idx_new.keys()) | set(idx_p2c.keys()) | set(idx_rch.keys()))
    if not all_months:
        lines.append("   âš ï¸ æ— æœˆåº¦æ•°æ®")
        lines.append("")
        return "\n".join(lines)

    header = (
        f"   {'æœˆä»½':<10}"
        f"{'æ–°äººæ•°':>8} {'æ–°äººæ­¥é•¿':>10}"
        f"{'æ–°æ™‹æ ¸':>8} {'æ™‹æ ¸è€—æ—¶':>10}"
        f"{'allä¸å¯è¾¾':>12} {'anyä¸å¯è¾¾':>12}"
    )
    lines.append(header)
    lines.append("   " + "-" * (len(header) - 3))

    for month in all_months:
        nm = idx_new.get(month, {})
        pm = idx_p2c.get(month, {})
        rm = idx_rch.get(month, {})

        newcomers = nm.get("newcomers", 0)
        avg_dist_m = nm.get("avg_shortest_path_to_core")

        new_core_count = pm.get("new_core_count", 0)
        avg_m2c_m = pm.get("avg_months_to_core")

        all_rate = rm.get("unreachable_to_all_core_rate")
        any_rate = rm.get("unreachable_to_any_core_rate")

        lines.append(
            f"   {month:<10}"
            f"{newcomers:>8} {(_fmt(avg_dist_m, ndigits=4)):>10}"
            f"{new_core_count:>8} {(_fmt(avg_m2c_m, ndigits=4)):>10}"
            f"{(_fmt_pct(all_rate, ndigits=2)):>12} {(_fmt_pct(any_rate, ndigits=2)):>12}"
        )

    lines.append("")
    return "\n".join(lines)


def _compute_sort_key(repo_data: Dict[str, Any]) -> float:
    """
    ç”¨äº --top çš„æ’åºï¼šé»˜è®¤æŒ‰å››ä¸ªä¸‰å±‚æ€»åˆ†ä¹‹å’Œï¼ˆè¶Šé«˜ä»£è¡¨å˜åŒ–/é£é™©ä¿¡å·è¶Šå¼ºï¼‰ã€‚
    è‹¥ç¼ºå¤±åˆ™é€€åŒ–ä¸º 0ã€‚
    """
    three = repo_data.get("three_layer_analysis", {}) or {}
    keys = [
        "newcomer_distance",
        "periphery_to_core_monthly",
        "unreachable_to_all_core_rate",
        "unreachable_to_any_core_rate",
    ]
    total = 0.0
    for k in keys:
        total += float((three.get(k, {}) or {}).get("total_score") or 0.0)
    return total


def main():
    parser = argparse.ArgumentParser(description="ç”Ÿæˆ Newcomer / Core-evolution è¯¦ç»†åˆ†ææŠ¥å‘Š")
    parser.add_argument(
        "--input",
        type=str,
        default="output/newcomer-analysis/full_analysis.json",
        help="è¾“å…¥çš„å®Œæ•´åˆ†ææ–‡ä»¶è·¯å¾„ï¼ˆnewcomer_analyzer è¾“å‡ºï¼‰",
    )
    parser.add_argument(
        "--output",
        type=str,
        default="output/newcomer-analysis/detailed_report.txt",
        help="è¾“å‡ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„",
    )
    parser.add_argument(
        "--repo",
        type=str,
        default=None,
        help="åªåˆ†ææŒ‡å®šçš„ä»“åº“ï¼ˆå¯ç”¨é€—å·åˆ†éš”å¤šä¸ªï¼‰",
    )
    parser.add_argument(
        "--top",
        type=int,
        default=None,
        help="åªè¾“å‡ºä¿¡å·å¼ºåº¦ï¼ˆå››ä¸ªä¸‰å±‚æ€»åˆ†ä¹‹å’Œï¼‰æœ€é«˜çš„å‰ N ä¸ªé¡¹ç›®",
    )

    args = parser.parse_args()

    input_path = Path(args.input)
    if not input_path.exists():
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
        return

    print(f"ğŸ“– è¯»å–åˆ†ææ•°æ®: {input_path}")
    with open(input_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    repos_to_analyze = list(data.keys())

    if args.repo:
        specified = [r.strip() for r in args.repo.split(",") if r.strip()]
        repos_to_analyze = [r for r in repos_to_analyze if r in specified]
        if not repos_to_analyze:
            print(f"âŒ æœªæ‰¾åˆ°æŒ‡å®šçš„ä»“åº“: {args.repo}")
            return

    repos_ranked: List[Tuple[str, float]] = []
    for repo in repos_to_analyze:
        key = _compute_sort_key(data[repo])
        repos_ranked.append((repo, key))

    repos_ranked.sort(key=lambda x: x[1], reverse=True)

    if args.top is not None:
        repos_ranked = repos_ranked[: args.top]

    if not repos_ranked:
        print("âŒ æ²¡æœ‰ç¬¦åˆæ¡ä»¶çš„é¡¹ç›®")
        return

    # ç”ŸæˆæŠ¥å‘Š
    reports: List[str] = []
    reports.append("=" * 90)
    reports.append("ğŸ” OSS é¡¹ç›® Newcomer / Core-evolution è¯¦ç»†åˆ†ææŠ¥å‘Š")
    reports.append("=" * 90)
    reports.append(f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    reports.append(f"åˆ†æé¡¹ç›®æ•°: {len(repos_ranked)}")
    reports.append("")

    for repo, _ in repos_ranked:
        reports.append(generate_repo_report(repo, data[repo]))

    full_report = "\n".join(reports)

    output_path = Path(args.output)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    with open(output_path, "w", encoding="utf-8") as f:
        f.write(full_report)

    print(f"âœ… æŠ¥å‘Šå·²ä¿å­˜: {output_path}")

    # æ§åˆ¶å°é¢„è§ˆ
    if len(repos_ranked) <= 3:
        print("\n" + full_report)
    else:
        print("\nğŸ“‹ å‰ 3 ä¸ªé¡¹ç›®é¢„è§ˆ:\n")
        for repo, _ in repos_ranked[:3]:
            print(generate_repo_report(repo, data[repo]))


if __name__ == "__main__":
    main()
