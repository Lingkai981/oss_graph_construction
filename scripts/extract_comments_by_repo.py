#!/usr/bin/env python3
"""
ä»æ•°æ®æ–‡ä»¶ç›´æ¥æå– GitHub Issue è¯„è®ºå’Œ PR Review è¯„è®ºå†…å®¹ï¼ˆæ— éœ€ API è°ƒç”¨ï¼‰

åŠŸèƒ½ï¼š
- éå†è¿‡æ»¤åçš„äº‹ä»¶æ•°æ®
- æŒ‰ä»“åº“ï¼ˆrepoï¼‰åˆ†ç»„ï¼Œé€ä¸ªä»“åº“æå–
- ç›´æ¥ä» payload.comment.body æå–è¯„è®ºå†…å®¹
- æ— éœ€è°ƒç”¨ GitHub APIï¼Œé¿å…é€Ÿç‡é™åˆ¶
- æ¯ä¸ªä»“åº“çš„è¯„è®ºä¿å­˜åˆ°å•ç‹¬çš„ JSON æ–‡ä»¶ï¼ˆ{url: body} æ˜ å°„ï¼‰

ä½¿ç”¨ï¼š
    python scripts/extract_comments_by_repo.py --data-dir data/filtered/ --output-dir data/comments_by_repo/
"""

import json
import argparse
from pathlib import Path
from typing import Dict, Set
from collections import defaultdict
from tqdm import tqdm
import re


class CommentExtractor:
    """GitHub è¯„è®ºæå–å™¨ï¼ˆä»æ•°æ®æ–‡ä»¶ç›´æ¥æå–ï¼Œæ— éœ€ APIï¼‰"""
    
    def __init__(self):
        """åˆå§‹åŒ–æå–å™¨"""
        pass
    
    @staticmethod
    def _repo_name_to_filename(repo_name: str) -> str:
        """
        å°†ä»“åº“åç§°è½¬æ¢ä¸ºå®‰å…¨çš„æ–‡ä»¶å
        
        Args:
            repo_name: ä»“åº“åç§°ï¼Œå¦‚ "denoland/deno"
        
        Returns:
            å®‰å…¨çš„æ–‡ä»¶åï¼Œå¦‚ "denoland-deno.json"
        """
        # å°† / æ›¿æ¢ä¸º -ï¼Œç§»é™¤å…¶ä»–ç‰¹æ®Šå­—ç¬¦
        safe_name = repo_name.replace("/", "-")
        # ç§»é™¤å…¶ä»–å¯èƒ½ä¸å®‰å…¨çš„å­—ç¬¦
        safe_name = re.sub(r'[<>:"|?*]', '_', safe_name)
        return f"{safe_name}.json"
    
    def _extract_comments_by_repo(
        self,
        data_dir: str,
        existing_repos: Dict[str, Dict[str, str]]
    ) -> Dict[str, Dict[str, str]]:
        """
        æŒ‰ä»“åº“æå–è¯„è®ºå†…å®¹
        
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            existing_repos: å·²æœ‰çš„ä»“åº“è¯„è®ºæ˜ å°„ {repo_name: {url: body}}ï¼ˆç”¨äºå»é‡ï¼‰
        
        Returns:
            {repo_name: {url: body}} å­—å…¸
        """
        data_path = Path(data_dir)
        files = sorted(data_path.glob("*-filtered.json"))
        
        print(f"ğŸ“ æ‰«æ {len(files)} ä¸ªæ•°æ®æ–‡ä»¶...")
        
        repo_comments = defaultdict(dict)  # {repo_name: {url: body}}
        
        for file_path in tqdm(files, desc="æ‰«æè¿›åº¦"):
            with open(file_path, "r", encoding="utf-8") as f:
                for line in f:
                    if not line.strip():
                        continue
                    try:
                        event = json.loads(line)
                    except json.JSONDecodeError:
                        continue
                    
                    event_type = event.get("type")
                    payload = event.get("payload", {})
                    repo = event.get("repo", {})
                    repo_name = repo.get("name", "unknown/unknown")
                    
                    # è·å–è¯¥ä»“åº“å·²æœ‰çš„è¯„è®ºï¼ˆç”¨äºå»é‡ï¼‰
                    existing_comments = existing_repos.get(repo_name, {})
                    
                    # Issue è¯„è®º
                    if event_type == "IssueCommentEvent":
                        comment = payload.get("comment", {})
                        url = comment.get("url")
                        body = comment.get("body")
                        
                        if url and body and url not in existing_comments:
                            repo_comments[repo_name][url] = body
                    
                    # PR Review è¯„è®º
                    elif event_type == "PullRequestReviewCommentEvent":
                        comment = payload.get("comment", {})
                        url = comment.get("url")
                        body = comment.get("body")
                        
                        if url and body and url not in existing_comments:
                            repo_comments[repo_name][url] = body
        
        return repo_comments
    
    def extract_comments_by_repo(
        self,
        data_dir: str,
        output_dir: str = "data/comments_by_repo/",
        resume: bool = True,
    ) -> Dict[str, Dict[str, str]]:
        """
        æŒ‰ä»“åº“æå–è¯„è®ºï¼ˆä»æ•°æ®æ–‡ä»¶ç›´æ¥æå–ï¼Œæ— éœ€ APIï¼‰
        æ¯ä¸ªä»“åº“çš„è¯„è®ºä¿å­˜åˆ°å•ç‹¬çš„ JSON æ–‡ä»¶
        
        Args:
            data_dir: æ•°æ®ç›®å½•è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•è·¯å¾„
            resume: æ˜¯å¦ä»å·²æå–çš„æ•°æ®æ¢å¤ï¼ˆè¿½åŠ æ¨¡å¼ï¼‰
        
        Returns:
            {repo_name: {url: body}} æ˜ å°„å­—å…¸
        """
        data_path = Path(data_dir)
        output_path = Path(output_dir)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_path.mkdir(parents=True, exist_ok=True)
        
        # åŠ è½½å·²æœ‰çš„ä»“åº“è¯„è®ºï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        existing_repos = {}
        if resume:
            # æ‰«æè¾“å‡ºç›®å½•ä¸­å·²æœ‰çš„æ–‡ä»¶
            for json_file in output_path.glob("*.json"):
                if json_file.name == "index.json":  # è·³è¿‡ç´¢å¼•æ–‡ä»¶
                    continue
                try:
                    with open(json_file, "r", encoding="utf-8") as f:
                        comments = json.load(f)
                        # ä»æ–‡ä»¶åæ¢å¤ä»“åº“åç§°ï¼ˆåå‘è½¬æ¢ï¼‰
                        repo_name = json_file.stem.replace("-", "/")
                        existing_repos[repo_name] = comments
                except (json.JSONDecodeError, Exception) as e:
                    print(f"âš ï¸  è·³è¿‡æ— æ•ˆæ–‡ä»¶: {json_file.name} ({e})")
            
            if existing_repos:
                total_existing = sum(len(comments) for comments in existing_repos.values())
                print(f"âœ… å·²åŠ è½½ {len(existing_repos)} ä¸ªä»“åº“çš„ {total_existing} æ¡å·²æå–è¯„è®º\n")
        
        # æŒ‰ä»“åº“æå–è¯„è®º
        repo_comments = self._extract_comments_by_repo(data_dir, existing_repos)
        
        # ç»Ÿè®¡ä¿¡æ¯
        total_new = sum(len(comments) for comments in repo_comments.values())
        print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   ä»“åº“æ•°é‡: {len(repo_comments)}")
        print(f"   æ–°æå–çš„è¯„è®º: {total_new}")
        if existing_repos:
            total_existing = sum(len(comments) for comments in existing_repos.values())
            print(f"   å·²æœ‰çš„è¯„è®º: {total_existing}")
            print(f"   æ€»è®¡: {total_new + total_existing} æ¡\n")
        else:
            print(f"   æ€»è®¡: {total_new} æ¡\n")
        
        if not repo_comments:
            print("âœ… æ‰€æœ‰è¯„è®ºå·²æå–å®Œæˆï¼")
            return existing_repos
        
        # æŒ‰ä»“åº“åç§°æ’åº
        sorted_repos = sorted(repo_comments.keys())
        
        print(f"â¬‡ï¸  å¼€å§‹æŒ‰ä»“åº“æå–è¯„è®ºï¼ˆæ— éœ€ API è°ƒç”¨ï¼‰\n")
        
        total_extracted = 0
        repo_index = {}  # ç”¨äºåˆ›å»ºç´¢å¼•æ–‡ä»¶
        
        # é€ä¸ªä»“åº“æå–
        for repo_idx, repo_name in enumerate(sorted_repos, 1):
            comments = repo_comments[repo_name]
            
            if not comments:
                continue
            
            # è·å–è¯¥ä»“åº“å·²æœ‰çš„è¯„è®ºï¼ˆå¦‚æœæœ‰ï¼‰
            existing_comments = existing_repos.get(repo_name, {})
            # åˆå¹¶æ–°æ—§è¯„è®º
            all_comments = {**existing_comments, **comments}
            
            print(f"\n{'=' * 60}")
            print(f"ğŸ“¦ ä»“åº“ {repo_idx}/{len(sorted_repos)}: {repo_name}")
            print(f"   æ–°æå–: {len(comments)} æ¡è¯„è®º")
            if existing_comments:
                print(f"   å·²æœ‰: {len(existing_comments)} æ¡è¯„è®º")
            print(f"   æ€»è®¡: {len(all_comments)} æ¡è¯„è®º")
            print(f"{'=' * 60}\n")
            
            # ç”Ÿæˆæ–‡ä»¶å
            filename = self._repo_name_to_filename(repo_name)
            output_file = output_path / filename
            
            # ä¿å­˜è¯¥ä»“åº“çš„è¯„è®ºåˆ°å•ç‹¬çš„æ–‡ä»¶
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(all_comments, f, ensure_ascii=False, indent=2)
            
            total_extracted += len(comments)
            
            # è®°å½•åˆ°ç´¢å¼•
            repo_index[repo_name] = {
                "filename": filename,
                "comment_count": len(all_comments),
                "new_comments": len(comments)
            }
            
            print(f"\nâœ… ä»“åº“ {repo_name} æå–å®Œæˆ: {len(comments)} æ¡æ–°è¯„è®ºï¼Œå…± {len(all_comments)} æ¡")
            print(f"   ä¿å­˜åˆ°: {output_file}")
        
        # ä¿å­˜ç´¢å¼•æ–‡ä»¶
        index_file = output_path / "index.json"
        with open(index_file, "w", encoding="utf-8") as f:
            json.dump(repo_index, f, ensure_ascii=False, indent=2)
        
        # ç»Ÿè®¡
        print("\n" + "=" * 60)
        print("âœ… æ‰€æœ‰ä»“åº“æå–å®Œæˆç»Ÿè®¡:")
        print(f"   æ–°æå–: {total_extracted} æ¡")
        print(f"   å¤„ç†ä»“åº“æ•°: {len(repo_comments)}")
        print(f"   è¾“å‡ºç›®å½•: {output_path}")
        print(f"   ç´¢å¼•æ–‡ä»¶: {index_file}")
        print("=" * 60)
        
        # åˆå¹¶æ‰€æœ‰ä»“åº“çš„è¯„è®ºè¿”å›
        all_repos = {**existing_repos}
        for repo_name, comments in repo_comments.items():
            if repo_name in all_repos:
                all_repos[repo_name].update(comments)
            else:
                all_repos[repo_name] = comments
        
        return all_repos


def main():
    parser = argparse.ArgumentParser(
        description="ä»æ•°æ®æ–‡ä»¶ç›´æ¥æå– GitHub Issue è¯„è®ºå’Œ PR Review è¯„è®ºï¼ˆæ— éœ€ APIï¼ŒæŒ‰ä»“åº“æå–ï¼Œæ¯ä¸ªä»“åº“ä¸€ä¸ªæ–‡ä»¶ï¼‰"
    )
    parser.add_argument(
        "--data-dir",
        type=str,
        default="data/filtered/",
        help="è¾“å…¥æ•°æ®ç›®å½•ï¼ˆé»˜è®¤: data/filtered/ï¼‰"
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default="data/comments_by_repo/",
        help="è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: data/comments_by_repo/ï¼‰"
    )
    parser.add_argument(
        "--resume",
        action="store_true",
        default=True,
        help="ä»å·²æå–æ•°æ®æ¢å¤ï¼ˆé»˜è®¤å¯ç”¨ï¼‰"
    )
    parser.add_argument(
        "--no-resume",
        dest="resume",
        action="store_false",
        help="ä¸ä»å·²æå–æ•°æ®æ¢å¤ï¼ˆè¦†ç›–å·²æœ‰æ–‡ä»¶ï¼‰"
    )
    
    args = parser.parse_args()
    
    print("=" * 60)
    print("GitHub è¯„è®ºæå–å™¨ï¼ˆä»æ•°æ®æ–‡ä»¶ç›´æ¥æå–ï¼Œæ— éœ€ APIï¼‰")
    print("æ¯ä¸ªä»“åº“çš„è¯„è®ºä¿å­˜åˆ°å•ç‹¬çš„ JSON æ–‡ä»¶")
    print("=" * 60)
    print(f"æ•°æ®ç›®å½•: {args.data_dir}")
    print(f"è¾“å‡ºç›®å½•: {args.output_dir}")
    print(f"æ¢å¤æ¨¡å¼: {'å¯ç”¨' if args.resume else 'ç¦ç”¨'}")
    print("=" * 60)
    print()
    
    extractor = CommentExtractor()
    extractor.extract_comments_by_repo(
        data_dir=args.data_dir,
        output_dir=args.output_dir,
        resume=args.resume,
    )


if __name__ == "__main__":
    main()

