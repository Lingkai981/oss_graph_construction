# 研究与设计决策：时序语义图构建（002-temporal-semantic-graph）

**目的**：整理本特性在技术选型、图建模方案、文件结构以及与 001 特性的关系上的关键决策，并给出理由与备选方案分析。  
**关联文档**：`specs/002-temporal-semantic-graph/spec.md`、`specs/002-temporal-semantic-graph/plan.md`

---

## 决策 1：图建模与导出库的选择

- **结论**：继续使用 `networkx` 作为图建模与导出 GraphML 的核心库。
- **理由**：
  - 当前项目中已经依赖 `networkx`，001 特性也基于该库进行快照图构建，延续可减少学习与维护成本。
  - `networkx` 原生支持有向图、带属性的节点与边，并内置 GraphML/JSON 等多种导出格式，符合规格对“语义属性 + GraphML/JSON 导出”的要求。
  - 对于单个一小时的 GitHub 事件数据，`networkx` 在性能与内存上足以满足需求，无需引入更复杂的分布式图系统。
- **备选方案**：
  - 直接基于自定义数据结构 + 手写 GraphML/JSON 序列化：灵活但工作量大，容易出错，不利于后续扩展。
  - 使用其他图数据库或图计算框架（如 Neo4j、Graph-tool）：对当前仅需离线构建与导出的场景过重，增加环境依赖与部署难度。

---

## 决策 2：事件文件解析方式

- **结论**：采用“逐行读取 + 标准库 `json` 解析”的方式处理 `2015-01-01-15.json`。
- **理由**：
  - GitHub 事件归档文件通常为“每行一个 JSON 对象”，逐行读取可以在内存和性能之间取得良好平衡。
  - 标准库 `json` 足以解析该结构，不需要引入额外 JSON 库；对于错误行可以捕获异常、记录日志并跳过。
  - 逐行流式解析方便未来扩展到更大时间范围或多个文件，而无需一次性加载全部内容到内存。
- **备选方案**：
  - 使用 `pandas.read_json` 直接读入 DataFrame：对行式 JSON 支持有限，且对当前需要的嵌套结构（`actor`、`repo`、`payload.commits` 等）仍需额外处理。
  - 先将文件转换为单个大 JSON 数组再解析：增加额外转换步骤，且对大文件不友好。

---

## 决策 3：图中实体与关系的粒度

- **结论**：在首版中引入以下图实体与关系：
  - 节点：事件、开发者、仓库、提交（来自 `payload.commits`）；
  - 关系边：
    - 开发者 → 事件：表示某开发者在某时间触发了某事件；
    - 事件 → 仓库：表示事件作用的目标仓库；
    - 事件 → 提交：对于 PushEvent，表示本次事件包含了哪些提交。
- **理由**：
  - 事件、开发者、仓库是行为分析的基础实体，提交节点则提供了更细粒度的代码层行为视角，有利于研究“单次 Push 内部结构”。
  - GitHub 事件数据天然提供 `payload.commits` 列表，构造提交节点不需要额外数据源，且语义清晰。
  - 通过事件节点作为中介，可以在需要时聚合出开发者-仓库关系，而无需在首版中直接建模所有长期关系边。
- **备选方案**：
  - 不引入提交节点，只将提交信息作为事件属性：图结构更简单，但丢失“提交间关系”的显式表达，不利于细粒度分析。
  - 额外引入 Issue、Pull Request 等更多实体：虽然更全面，但在单小时数据上会显著增加复杂度，本特性目标是先把“事件-开发者-仓库-提交”这条主链打通。

---

## 决策 4：事件范围与事件类型

- **结论**：
  - 事件范围：**保留该一小时内所有仓库的事件**，不过滤到单一项目或仓库。
  - 事件类型：首版**保留所有类型事件**，不进行类型级白名单过滤。
- **理由**：
  - 该数据集本身就是对 GitHub 全局行为的一小时切片，覆盖所有仓库更符合“全局行为刻画”的研究背景。
  - 不做类型过滤可以完整保留“行为多样性”，包括 WatchEvent 等弱信号行为，便于后续探索性分析。
  - 后续如需聚焦特定仓库或事件类型，可以在分析或上层工具中做二次过滤，而不必在构图阶段提前丢弃信息。
- **备选方案**：
  - 仅保留 PushEvent / CreateEvent / PullRequestEvent 等强行为事件：更贴近“代码贡献”视角，但会丢掉部分重要上下文行为。
  - 在本特性中引入可配置事件类型白名单：灵活但会增加首版实现与配置复杂度，目前先保持简单。

---

## 决策 5：与 001 特性的代码隔离方式

- **结论**：在同一 `src` 根目录下，通过**新增子目录**来承载时序语义图相关实现，与 001 特性的快照式代码以模块级进行区分，而不创建新的顶层项目。
- **理由**：
  - 用户要求“代码文件可以通过子目录的方式和之前001分支的代码进行区分”，子目录是最直接、对现有结构侵入最小的方案。
  - 继续使用统一的 CLI 入口与工具模块（如 logger、导出器），既保证复用，又能在目录结构层面看出不同特性的职责边界。
- **备选方案**：
  - 新建顶层子包或独立服务（例如 `temporal_semantic_graph/`）：结构更明显，但对当前项目规模来说略显过重。
  - 与 001 特性混合在同一文件中通过条件分支区分逻辑：短期工作量小，但长期维护成本高，不利于理解与测试。

---

## 决策 6：导出格式与文件命名

- **结论**：导出 JSON 与 GraphML 两种格式，文件统一放置在 `output/temporal-semantic-graph/` 目录，并在文件名中包含时间窗口信息（如 `temporal-graph-2015-01-01-15.json` / `.graphml`）。
- **理由**：
  - 独立的输出子目录有助于与 001 特性的快照输出区分，避免混淆。
  - 文件名中包含时间窗口信息，便于在未来扩展到多小时、多文件时进行管理与检索。
- **备选方案**：
  - 与 001 共用同一输出目录：不利于区分两种图的语义与用途。
  - 只导出一种格式：会限制下游工具选择（例如很多图工具更偏好 GraphML）。

---

## 决策 7：测试策略

- **结论**：采用“单元测试 + 集成测试”组合：
  - 单元测试覆盖：事件解析、图构建、属性填充、导出函数等核心逻辑。
  - 集成测试覆盖：从样例 JSON 文件到最终导出的 JSON/GraphML 文件的端到端流程。
- **理由**：
  - 时序语义图构建涉及多步转换（解析 → 建模 → 导出），仅靠单元测试无法保证整体契约的正确性。
  - 集成测试可以对关键指标（节点数、边数、属性字段存在性）进行断言，验证整体行为是否符合规格。
- **备选方案**：
  - 只做单元测试：难以发现数据流跨模块传递时的兼容性问题。
  - 引入更重的契约测试框架：对当前 CLI 型工具来说暂时没有必要。

---

## 决策 8：语义评分（importance / influence / contribution）的计算方式

- **结论**：
  - 事件重要性 `importance_score`：基于事件类型权重和提交数量计算原始得分，再使用 **min-max 归一化** 映射到 \[0,1]；
  - 开发者影响力 `influence_score`：累加其参与事件的重要性得分，并对跨仓库活动数量进行对数放大加成，同样通过 min-max 归一化映射到 \[0,1]；
  - 贡献强度 `contribution_strength`：定义为“开发者影响力 × 事件重要性”的乘积，直接落在 \[0,1] 区间。
- **计算规则概述**：
  - 事件原始重要度：
    - 为不同事件类型设置基础权重（例如：`PushEvent` 3.0、`CreateEvent` 2.0、`PullRequestEvent` 2.0、`IssuesEvent`/`IssueCommentEvent` 1.5、`WatchEvent` 1.0，其余类型默认 1.0）；
    - 对于 `PushEvent`，根据 `payload.commits` 的长度使用对数放大因子 `log1p(len(commits))`，得到 `raw_imp = base_weight * log1p(commit_count)`；
    - 对于 `PullRequestEvent` 等没有 `commits` 列表但有 `pull_request.commits` 计数的信息，可在后续迭代中扩展使用类似规则。
  - 开发者原始影响力：
    - 对每个事件，将该事件的 `raw_imp` 加到触发该事件的 `actor.id` 上；
    - 统计每个开发者涉及的不同 `repo.id` 数量 `repo_count`，并追加跨仓库加成 `cross_bonus = α * log1p(repo_count)`（当前实现中 `α` 为一个常量系数，例如 0.5）；
    - 得到 `actor_influence_raw = sum(raw_imp) + cross_bonus`。
  - 归一化：
    - 对事件和开发者分别使用 min-max 归一化：
      - 若所有值相同，则统一设为 1.0（避免全 0 失去区分度）；
      - 否则 `score_norm = (v - min) / (max - min)`，稳定映射到 \[0,1] 同时保留相对差异。
  - 边级贡献强度：
    - 对于一条开发者→事件边，`contribution_strength = influence_score(actor) * importance_score(event)`。
- **理由**：
  - 使用类型权重 + 对数因子，可以增强对“高贡献事件”（例如包含提交的 Push）的敏感度，又不会让提交数量线性放大导致极端值；
  - min-max 归一化比单纯的“除以最大值”更稳定，可以在存在明显长尾时仍保留中间区域的区分度；
  - 开发者跨仓库活动数量是影响力的重要信号，但通过 `log1p` 限制其增长，可以避免少量“扫星式 watch”行为在数值上压倒真正持续贡献的开发者；
  - 定义 `contribution_strength = influence × importance` 使得“强开发者做的重要事件”在数值上自然突出，便于下游分析按该指标排序或过滤。
- **备选方案与后续优化方向**：
  - 可以在未来通过配置文件将类型权重、加成系数 `α`、是否采用 min-max 或其他归一化方式（如分位数归一化、Z-score）开放出来；
  - 可在更大时间窗口上引入图算法（如 PageRank、中心性指标）进一步丰富语义评分，但当前特性限定在单小时范围内，优先采用简单、可解释且完全基于本文件数据的方案。

---

## 小结

通过上述决策，本特性在以下方面已经达成清晰共识：  
（1）基于现有 Python/`networkx` 技术栈实现一小时 GitHub 事件的时序语义图构建；  
（2）在源码与输出目录上通过子目录区分，与 001 特性形成清晰边界；  
（3）在图建模粒度上引入事件、开发者、仓库、提交四类节点和关键关系；  
（4）在首版中保留所有事件与仓库，以便进行更广泛的行为分析；  
（5）在语义层面，通过可解释的、归一化的评分机制刻画事件重要性与开发者影响力，并在边上编码贡献强度，支持后续分析与推理。  
后续在 `data-model.md` 与 `contracts/` 中将根据这些决策进一步细化实体字段和 CLI 使用方式。


