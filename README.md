# OSS 社区健康度分析工具

基于 GitHub Archive 事件数据，构建多类型时序图并进行维护者倦怠（Burnout）分析的工具集。

## 功能概览

```
┌─────────────────────────────────────────────────────────────────┐
│                      OSS 社区健康度分析                          │
├─────────────────────────────────────────────────────────────────┤
│  1. 数据采集        从 GitHub Archive 下载并过滤代表性项目数据    │
│  2. 三类图构建      Actor-Actor / Actor-Repo / Actor-Discussion  │
│  3. 倦怠分析        三层架构评分 + 多维度预警                     │
│  4. 详细报告        按项目输出完整分析过程                        │
└─────────────────────────────────────────────────────────────────┘
```

## 快速开始

### 1. 安装依赖

```bash
python -m venv venv
source venv/bin/activate  # Linux/macOS
pip install -r requirements.txt
```

### 2. 数据采集（可选）

如果需要采集新数据：

```bash
# 下载 2023-2025 年数据（月采样模式，约 36GB）
python -m src.data_collection.gharchive_collector \
  --start-date 2023-01-01 \
  --end-date 2025-12-31 \
  --sample-mode monthly \
  --output-dir data/filtered
```

### 3. 构建月度图

```bash
python -m src.analysis.monthly_graph_builder \
  --data-dir data/filtered \
  --output-dir output/monthly-graphs \
  --workers 4
```

### 4. 运行倦怠分析

```bash
python -m src.analysis.burnout_analyzer \
  --graphs-dir output/monthly-graphs \
  --output-dir output/burnout-analysis
```

### 5. 查看详细报告

```bash
# 查看前 10 个高风险项目
python -m src.analysis.detailed_report --top 10

# 查看指定项目
python -m src.analysis.detailed_report --repo "kubernetes/kubernetes"
```

---

## 三类图构建详解

### 图类型说明

| 图类型 | 节点 | 边 | 适用分析 |
|-------|------|-----|---------|
| **Actor-Actor** | 开发者 | 协作/评审/回复关系 | 核心成员识别、协作网络 |
| **Actor-Repo** | 开发者 + 仓库 | 贡献关系 | 贡献者分析、项目热度 |
| **Actor-Discussion** | 开发者 + Issue/PR | 参与讨论关系 | 社区互动、新人融入 |

### 构建流程概览

```
GitHub Archive 事件数据
    ↓
按月聚合（2023-01, 2023-02, ...）
    ↓
按项目分组（angular-angular, kubernetes-kubernetes, ...）
    ↓
为每个项目的每个月构建三类图
    ├── Actor-Actor 图
    ├── Actor-Repo 图
    └── Actor-Discussion 图
    ↓
导出为 GraphML 格式
```

---

### Actor-Actor 图构建

#### 边的产生规则

两个 Actor 之间产生边的条件：

**1. 直接交互关系**

| 边类型 | 触发事件 | 关系说明 |
|-------|---------|---------|
| `ISSUE_INTERACTION` | `IssueCommentEvent` | Actor A 在 Actor B 创建的 Issue 中发表评论（A → B） |
| `PR_REVIEW` | `PullRequestReviewCommentEvent` | Actor A 在 Actor B 创建的 PR 中发表代码审查评论（A → B） |
| `PR_MERGE` | `PullRequestEvent` (action=closed, merged=true) | Actor A 合并了 Actor B 创建的 PR（A → B） |

**2. 共同参与关系**

| 边类型 | 触发条件 | 关系说明 |
|-------|---------|---------|
| `ISSUE_CO_PARTICIPANT` | 两个 Actor 都参与了同一个 Issue 的讨论 | 即使没有直接回复，但都参与了同一 Issue，存在协作关系（双向边） |

**构建逻辑说明**：

1. **Issue 交互**：
   - 当 `IssueCommentEvent` 发生时，系统会识别该 Issue 的创建者
   - 如果评论者不是创建者本人，则创建 `ISSUE_INTERACTION` 边：评论者 → Issue 创建者

2. **PR 审查**：
   - 当 `PullRequestReviewCommentEvent` 发生时，系统会识别该 PR 的创建者
   - 如果评论者不是创建者本人，则创建 `PR_REVIEW` 边：评论者 → PR 创建者

3. **PR 合并**：
   - 当 `PullRequestEvent` 且 `action=closed` 且 `merged=true` 时
   - 创建 `PR_MERGE` 边：合并者 → PR 创建者

4. **共同参与者**：
   - 系统会跟踪每个 Issue 的所有参与者（所有在该 Issue 中发表评论的开发者）
   - 对于每个 Issue，将其所有参与者两两之间建立 `ISSUE_CO_PARTICIPANT` 边
   - 这确保了即使没有直接交互（比如两个评论者都回复了创建者，但彼此没有回复），但参与同一讨论的开发者之间也有连接
   - 注意：Issue 创建者会通过 `ISSUE_INTERACTION` 边与所有评论者连接，所以即使创建者不在 `ISSUE_CO_PARTICIPANT` 集合中，也能通过其他边与其他参与者连通

**图结构**：
- 类型：`MultiDiGraph`（支持多重边，同一对 Actor 可以有不同类型的多条边）
- 节点：`actor:{actor_id}`
- 边属性：
  - `edge_type`: 边类型（`ISSUE_INTERACTION`、`PR_REVIEW`、`PR_MERGE`、`ISSUE_CO_PARTICIPANT`）
  - `created_at`: 事件发生时间（`ISSUE_CO_PARTICIPANT` 可能为空）
  - `key`: 唯一标识（`{edge_type}_{event_id}`）
  - `comment_body`: 评论内容（仅 `ISSUE_INTERACTION` 和 `PR_REVIEW` 有）

**特点**：
- **每个事件 = 一条独立边**：同一对 Actor 的多次交互会创建多条边
- **有向边**：`A → B` 表示 A 对 B 的某种行为（回复、审查、合并等）
- **共同参与者是双向的**：`ISSUE_CO_PARTICIPANT` 边在图中是双向的（实际存储为两条有向边）
- **保留完整信息**：每条边都保留原始事件的时间、内容等属性

**用途**：
- k-core 分解识别核心成员
- 度中心性分析协作活跃度
- 社区结构分析
- 协作网络可视化

---

### Actor-Repo 图构建

#### 边的产生规则

**所有 GitHub 事件都会在 Actor 和 Repo 之间创建一条边**（Actor → Repo）

| 边类型 | 触发事件 | 关系说明 |
|-------|---------|---------|
| `PUSH` | `PushEvent` | Actor 向仓库推送代码 |
| `CREATE` | `CreateEvent` | Actor 在仓库中创建分支/标签等 |
| `PR` | `PullRequestEvent` | Actor 对仓库进行 PR 操作（打开/关闭/合并） |
| `ISSUE` | `IssuesEvent` | Actor 对仓库进行 Issue 操作（打开/关闭） |
| `COMMENT` | `IssueCommentEvent` | Actor 在仓库的 Issue 中发表评论 |
| `REVIEW` | `PullRequestReviewCommentEvent` | Actor 在仓库的 PR 中发表代码审查评论 |
| `STAR` | `WatchEvent` | Actor 给仓库点星 |
| `FORK` | `ForkEvent` | Actor Fork 仓库 |
| `DELETE` | `DeleteEvent` | Actor 在仓库中删除分支/标签等 |
| `RELEASE` | `ReleaseEvent` | Actor 在仓库中发布版本 |

**关键特点**：
- **每个事件 = 一条独立边**：同一 Actor 对同一 Repo 的多次操作会创建多条边
- **保留完整时间信息**：每条边都有 `created_at` 属性
- **支持评论内容**：`COMMENT` 和 `REVIEW` 类型的边包含 `comment_body` 属性

**图结构**：
- 类型：`MultiDiGraph`（支持多重边）
- 节点：
  - `actor:{actor_id}`：开发者节点
  - `repo:{repo_id}`：仓库节点
- 边属性：
  - `edge_type`: 边类型
  - `created_at`: 事件发生时间
  - `key`: 唯一标识（`{edge_type}_{event_id}`）
  - `comment_body`: 评论内容（仅 `COMMENT` 和 `REVIEW` 类型有）

**用途**：
- 贡献者活跃度分析
- 事件时序分析
- 仓库热度排名
- 贡献模式识别

---

### Actor-Discussion 图构建

#### 边的产生规则

**Issue 相关边**（Actor → Issue）：

| 边类型 | 触发事件 | 关系说明 |
|-------|---------|---------|
| `CREATED_ISSUE` | `IssuesEvent` (action=opened) | Actor 创建了 Issue |
| `CLOSED_ISSUE` | `IssuesEvent` (action=closed) | Actor 关闭了 Issue |
| `COMMENTED_ISSUE` | `IssueCommentEvent` | Actor 在 Issue 中发表评论 |

**PR 相关边**（Actor → PullRequest）：

| 边类型 | 触发事件 | 关系说明 |
|-------|---------|---------|
| `CREATED_PR` | `PullRequestEvent` (action=opened) | Actor 创建了 PR |
| `MERGED_PR` | `PullRequestEvent` (action=closed, merged=true) | Actor 合并了 PR |
| `CLOSED_PR` | `PullRequestEvent` (action=closed, merged=false) | Actor 关闭了 PR（未合并） |
| `PR_ACTION` | `PullRequestEvent` (其他 action) | Actor 对 PR 进行了其他操作 |
| `REVIEWED_PR` | `PullRequestReviewCommentEvent` | Actor 在 PR 中发表代码审查评论 |

**关键特点**：
- **每个事件 = 一条独立边**：同一 Actor 对同一 Discussion 的多次操作会创建多条边
- **Discussion 节点自动创建**：当首次遇到某个 Issue/PR 时，系统会自动创建对应的 Discussion 节点
- **保留评论内容**：`COMMENTED_ISSUE` 和 `REVIEWED_PR` 类型的边包含 `comment_body` 属性（用于情感分析）
- **跟踪参与者**：系统会跟踪每个 Discussion 的所有参与者（包括创建者和所有评论者）

**图结构**：
- 类型：`MultiDiGraph`（支持多重边）
- 节点：
  - `actor:{actor_id}`：开发者节点
  - `issue:{repo_id}:{number}`：Issue 节点（如 `issue:12345:678`）
  - `pr:{repo_id}:{number}`：PR 节点（如 `pr:12345:789`）
- 边属性：
  - `edge_type`: 边类型
  - `created_at`: 事件发生时间
  - `key`: 唯一标识（`{edge_type}_{event_id}`）
  - `comment_body`: 评论内容（仅 `COMMENTED_ISSUE` 和 `REVIEWED_PR` 类型有）

**Discussion 节点属性**：
- `node_type`: "Issue" 或 "PullRequest"
- `number`: Issue/PR 编号
- `title`: Issue/PR 标题
- `state`: 状态（open/closed）
- `creator_id` / `creator_login`: 创建者信息
- `created_at`: 创建时间
- `comment_count`: 评论数量
- `participants`: 参与者集合（用于分析）

**用途**：
- 讨论参与度分析
- 新人融入轨迹
- 社区互动模式
- 情感分析（基于 `comment_body`）

---

### 图构建的技术细节

#### 1. 时间聚合

- 从日粒度数据（`data/filtered/YYYY-MM-DD-HH-filtered.json`）聚合到月粒度
- 将同一月份的所有事件按项目分组
- 为每个项目的每个月构建三类图

#### 2. 节点属性

**Actor 节点**：
- `node_type`: "Actor"
- `actor_id`: 开发者 ID
- `login`: GitHub 用户名
- `event_count`: 该月事件总数
- `event_types`: 各类事件计数（JSON 字符串）

**Repository 节点**：
- `node_type`: "Repository"
- `repo_id`: 仓库 ID
- `name`: 仓库全名（owner/repo）
- `event_count`: 该月事件总数
- `event_types`: 各类事件计数（JSON 字符串）

**Discussion 节点**（Issue/PR）：
- `node_type`: "Issue" 或 "PullRequest"
- `number`: Issue/PR 编号
- `title`: 标题
- `state`: 状态（open/closed）
- `creator_id` / `creator_login`: 创建者信息
- `created_at`: 创建时间
- `comment_count`: 评论数量

#### 3. 边属性

**所有边都包含**：
- `edge_type`: 边类型（如 `ISSUE_INTERACTION`、`PUSH`、`CREATED_ISSUE`）
- `created_at`: 事件发生时间（ISO 格式）
- `key`: 唯一标识（`{edge_type}_{event_id}`）

**特定边类型的额外属性**：
- `comment_body`: 评论内容（`ISSUE_INTERACTION`、`PR_REVIEW`、`COMMENTED_ISSUE`、`REVIEWED_PR`）

#### 4. 并行处理

- 使用 `multiprocessing.Pool` 并行构建多个项目的图
- 可通过 `--workers` 参数控制并行进程数
- 每个进程独立处理一个项目的月度图构建

---

## 倦怠分析算法详解

### 分析流程概览

```
月度图数据（Actor-Actor 图）
    ↓
计算月度指标
    ├── 基础网络指标（节点数、边数、密度）
    ├── 度中心性统计
    ├── 核心成员识别（重点）
    └── 边类型分布
    ↓
时间序列分析
    ├── 活跃度趋势
    ├── 贡献者趋势
    ├── 核心成员稳定性
    └── 协作密度趋势
    ↓
三层架构评分
    ├── 长期趋势（40%）
    ├── 近期状态（40%）
    └── 稳定性（20%）
    ↓
综合倦怠评分（0-100分）
```

---

### 月度指标计算详解

对每个月的 Actor-Actor 图，计算以下指标：

#### 1. 基础网络指标

**节点数（node_count）**：
- 直接统计图中的节点总数
- 每个节点代表一个开发者（Actor）

**边数（edge_count）**：
- 直接统计图中的边总数
- 每条边代表一次协作关系（如 PR 审查、Issue 回复等）

**网络密度（density）**：
- 计算公式：`density = edge_count / (node_count × (node_count - 1))`
- 对于有向图，最大可能边数为 `node_count × (node_count - 1)`
- 密度范围：0（无连接）到 1（完全连接）
- 密度越高，说明成员之间协作越频繁

**示例**：
- 节点数：50
- 边数：200
- 最大可能边数：50 × 49 = 2450
- 密度：200 / 2450 = 0.082

---

#### 2. 活跃度指标

**事件总数（total_events）**：
- 从图的元数据中获取：`graph.graph.get("total_events", 0)`
- 表示构建该图时使用的原始事件总数
- 注意：这个值可能大于边数，因为一个事件可能产生多条边（如共同参与者边）

**活跃贡献者数（unique_actors）**：
- 从图的元数据中获取：`graph.graph.get("actor_count", node_count)`
- 如果元数据中没有，则使用节点数作为近似值
- 表示该月参与项目的不同开发者数量

---

#### 3. 度中心性统计

**度数（degree）**：
- 对每个节点：`度数 = 入度 + 出度`
- 入度：指向该节点的边数
- 出度：从该节点发出的边数
- 度数反映该开发者与其他人的交互次数

**度中心性统计量**：
- **平均度数（degree_mean）**：`Σ度数 / 节点数`
- **最大度数（degree_max）**：所有节点度数的最大值
- **度数标准差（degree_std）**：
  - 方差：`variance = Σ(度数 - 平均度数)² / 节点数`
  - 标准差：`degree_std = √variance`
  - 标准差大说明度数分布不均匀，存在"头部效应"

**示例**：
- 节点度数：[50, 30, 20, 15, 10, 8, 5, 3, 2, 1]
- 平均度数：14.4
- 最大度数：50
- 标准差：15.8（说明分布不均匀，少数人贡献了大部分交互）

---

#### 4. 边类型分布

**计算方法**：
1. 遍历图中的所有边
2. 统计每种边类型的数量
3. 得到边类型计数字典：`{edge_type: count}`

**边类型**：
- `ISSUE_INTERACTION`：Issue 交互
- `PR_REVIEW`：PR 审查
- `PR_MERGE`：PR 合并
- `ISSUE_CO_PARTICIPANT`：共同参与 Issue

**用途**：了解协作模式，例如 PR 审查多还是 Issue 讨论多。

---

#### 5. 核心成员识别

详见下一节"核心成员识别算法详解"。

---

### 核心成员识别算法详解

#### 为什么需要识别核心成员？

核心成员是项目的关键维护者，他们的流失或活跃度下降是倦怠的重要信号。

#### 算法步骤

**步骤 1：计算加权度数**

**计算方法**：
1. 对每个节点，遍历其所有出边和入边
2. 根据每条边的 `edge_type` 查找对应的权重
3. 累加所有权重得到该节点的加权度数

**权重查找规则**：
- 如果边类型在权重配置中，使用配置的权重
- 如果边类型不在配置中，使用默认权重 1.0

**示例**：
- 节点 A 有 10 条 `PR_MERGE` 边（权重 3.0）和 5 条 `ISSUE_INTERACTION` 边（权重 0.5）
- 加权度数 = `10 × 3.0 + 5 × 0.5 = 32.5`

**步骤 2：计算原始度数**

- 直接使用 NetworkX 的 `graph.degree()` 函数
- 原始度数 = 入度 + 出度（不考虑权重）
- 用于兼容性和显示

**步骤 3：计算 k-core 分解**

**k-core 算法**：
1. 将图转换为无向图
2. 迭代移除度数小于 k 的节点
3. 对每个节点，找到它能保留的最大 k 值
4. 这个 k 值就是该节点的 k-core 值

**k-core 值的含义**：
- k=1：节点至少连接 1 个其他节点
- k=2：节点至少连接 2 个其他节点（且这 2 个节点之间也相互连接）
- k 值越高，说明节点越处于网络的紧密核心区域

**为什么使用 k-core？**

k-core 分解用于识别节点在网络结构中的核心位置，这是对加权度数的必要补充：

1. **度中心性的局限性**：
   - 加权度数只考虑直接连接数和边权重，忽略了网络结构位置
   - 可能高估"边缘活跃者"：连接数多但主要与边缘贡献者交互
   - 可能低估"结构关键者"：连接数少但处于网络核心位置

2. **k-core 的优势**：
   - **结构核心识别**：k-core 值反映节点在紧密子图中的位置，即使度数不高，如果处于高 k-core，说明它连接的都是核心节点
   - **区分边缘与核心**：能区分"边缘活跃者"（高度数、低 k-core）和"结构关键者"（中等度数、高 k-core）
   - **网络位置重要性**：即使贡献不是最多，但如果处于网络中心，在协作中也很重要

3. **实际场景示例**：

   ```
   场景 A：边缘活跃者
   开发者 X：加权度数 50，但主要与边缘贡献者交互
   - 加权度数：高（50）
   - k-core：低（k=1 或 2）
   - 实际地位：边缘活跃，不是核心
   
   场景 B：结构关键者
   开发者 Y：加权度数 20，但与所有核心维护者都有交互
   - 加权度数：中等（20）
   - k-core：高（k=4 或 5）
   - 实际地位：结构关键，是核心
   ```

   如果只用加权度数，X 可能排在 Y 前面，但 Y 更可能是真正的核心成员。

**步骤 4：计算综合得分**

**计算方法**：
1. **归一化加权度数**：`加权度数归一化 = 节点加权度数 / 最大加权度数`
   - 将加权度数归一化到 [0, 1] 区间
   - 最大加权度数是所有节点中加权度数的最大值
2. **归一化 k-core**：`k-core归一化 = 节点k-core值 / 最大k-core值`
   - 将 k-core 值归一化到 [0, 1] 区间
   - 最大 k-core 值是所有节点中 k-core 值的最大值
3. **综合得分**：`得分 = 0.5 × 加权度数归一化 + 0.5 × k-core归一化`
   - 加权贡献量和网络位置各占 50%

**为什么是 50/50 的比例？**

这个比例设计考虑了实际贡献和网络结构的平衡：

1. **50% 加权贡献量（实际贡献）**：
   - **重要性**：实际贡献（PR 合并、代码审查等）直接体现开发者的价值
   - **避免过度依赖结构**：仅看网络结构可能选出"连接多但贡献少"的节点
   - **符合直觉**：贡献多的人更可能是核心成员

2. **50% 网络位置（结构重要性）**：
   - **捕捉结构重要性**：即使贡献不是最多，但如果处于网络中心，在协作中也很关键
   - **识别桥梁角色**：连接不同子社区的关键人物，可能贡献不是最多但结构上很重要
   - **防止遗漏**：避免只选"孤立的贡献大户"，忽略协作网络中的关键节点

3. **50/50 比例的合理性**：
   - **平衡设计**：实际贡献和网络结构同等重要，避免过度偏向任何一方
   - **适应性强**：对于不同类型的项目（代码库 vs 社区项目）都能适用
   - **互补性**：两个指标互补，加权度数捕捉"贡献大户"，k-core 捕捉"结构关键者"

**边权重配置**：

| 边类型 | 权重 | 说明 |
|-------|------|------|
| `PR_MERGE` | 3.0 | 合并 PR（高价值贡献） |
| `PR_REVIEW` | 1.5 | PR 代码审查（中等价值） |
| `ISSUE_INTERACTION` | 0.5 | Issue 评论（参与度） |
| `ISSUE_CO_PARTICIPANT` | 0.5 | 共同参与 Issue（参与度） |
| 其他 | 1.0 | 默认权重 |

**权重设计合理性**：
- **PR_MERGE (3.0)**：最高权重，体现核心维护者的关键职责
- **PR_REVIEW (1.5)**：中等权重，代码审查体现技术贡献
- **参与类 (0.5)**：较低权重，体现社区参与度
- **权重比例 6:3:1**：清晰的贡献价值层次

**k-core 分解说明**：
- k-core 是图的一个子图，其中每个节点的度数至少为 k
- 通过迭代移除度数小于 k 的节点，得到 k-core
- k 值越高，说明节点越处于网络的紧密核心

**示例**：
```
原始图：
A ── B ── C
│    │    │
D ── E ── F
     │
     G

1-core: 所有节点（每个节点至少连接 1 个）
2-core: A, B, C, D, E, F（移除 G，因为 G 只连接 1 个）
3-core: B, E（只有这两个节点至少有 3 个连接）
```

**步骤 5：按综合得分排序**

- 将所有节点按综合得分从高到低排序
- 得分高的节点排在前面，优先被选为核心成员

**步骤 6：双重约束动态筛选**

**约束 1：贡献阈值（50%）**
- 计算总加权度数：`总加权度数 = Σ所有节点的加权度数`
- 贡献阈值：`阈值 = 总加权度数 × 0.5`
- 从高到低累加节点的加权度数（使用加权度数，考虑边类型权重）
- 当累计加权度数 ≥ 阈值时，停止添加

**约束 2：得分阈值（平均得分）**
- 计算所有节点的平均综合得分
- 如果当前节点的得分 < 平均得分，且已有至少 3 个核心成员，则停止添加
- 这确保核心成员的得分都高于平均水平

**筛选过程**：
1. 从得分最高的节点开始
2. 依次检查每个节点
3. 如果满足以下任一条件，停止添加：
   - 累计加权贡献 ≥ 50% 总贡献
   - 得分 < 平均得分（且已有 ≥3 人）
4. 否则，将该节点加入核心成员列表

**双重约束的含义**：

| 约束 | 条件 | 目的 |
|-----|------|------|
| **贡献阈值** | 累计加权贡献 ≥ 50% | 确保核心成员覆盖主要贡献（使用加权度数，考虑边类型权重） |
| **得分阈值** | 得分 ≥ 平均得分（且已有≥3人） | 排除边缘贡献者 |

**步骤 7：兜底保障**

**条件检查**：
- 如果筛选后核心成员数 < 2，且总节点数 ≥ 2
- 则强制将得分最高的前 2 个节点加入核心成员
- 确保至少识别出 2 个核心成员（即使他们不满足其他约束条件）

#### 算法示例

假设一个项目有 10 个开发者，月度交互情况如下：

```
开发者    原始度数  加权度数   k-core    归一化加权度  归一化k-core  综合得分
A         50       120.0     5         1.0          1.0          1.0
B         30       60.0      4         0.5          0.8          0.65
C         20       30.0      3         0.25         0.6          0.425
D         15       22.5      2         0.188        0.4          0.294
E         10       15.0      2         0.125        0.4          0.263
F         8        4.0       1         0.033        0.2          0.117
G         5        2.5       1         0.021        0.2          0.111
H         3        1.5       1         0.013        0.2          0.107
I         2        1.0       1         0.008        0.2          0.104
J         1        0.5       1         0.004        0.2          0.102

总加权度数：257.5
总人数：10
最大加权度数：120.0
最大k-core：5
```

**综合得分计算示例（以B为例）**：
- 归一化加权度数：`60.0 / 120.0 = 0.5`
- 归一化k-core：`4 / 5 = 0.8`
- 综合得分：`0.5 × 0.5 + 0.5 × 0.8 = 0.25 + 0.4 = 0.65`

**说明**：
- A 的加权度数高（120.0）可能是因为有很多 PR_MERGE（权重 3.0）和 PR_REVIEW（权重 1.5）
- A 的 k-core 值也最高（5），说明它处于网络的最核心位置
- B 虽然加权度数只有 A 的一半，但 k-core 值较高（4），说明它在网络结构中也处于核心位置
- F-J 的加权度数和 k-core 都较低，说明它们既贡献少，也不在网络核心位置

**筛选过程**：

```
1. 按综合得分排序：A > B > C > D > E > F > G > H > I > J

2. 开始筛选（使用加权度数）：
   - A: 加权贡献 120.0，累计 120.0/257.5 = 46.6% < 50%，继续
   - B: 加权贡献 60.0，累计 180.0/257.5 = 69.9% ≥ 50%，停止（贡献阈值）

3. 核心成员：A, B（2人，加权贡献 69.9%）
```

**说明**：
- 使用加权度数计算，考虑边类型权重（PR_MERGE=3.0, PR_REVIEW=1.5, ISSUE_INTERACTION=0.5等）
- 贡献阈值设为50%，确保核心成员覆盖至少一半的加权贡献
- 不再限制人数上限，完全由贡献阈值和得分阈值决定
- 如果B的得分低于平均得分，且已有至少3人，也会停止（但此例中只有2人，所以不触发得分阈值）

**对比原始算法**（不使用权重）：
- 原始算法可能选 A, B, C, D（4人）
- 加权算法选 A, B（2人），更聚焦于高价值贡献者

---

### 三层评分架构详解

每个维度（活跃度、贡献者、核心成员、协作密度）都使用三层分析，总分 25 分：

#### 1. 长期趋势（40%权重，满分 10 分）

**计算方法**：
1. **数据归一化**：将时间序列值除以第一个非零值，得到归一化序列
2. **线性回归**：使用最小二乘法拟合整个时间序列
   - x 轴：月份索引（0, 1, 2, ..., n-1）
   - y 轴：归一化后的数值
   - 斜率公式：`slope = Σ(xᵢ-x̄)(yᵢ-ȳ) / Σ(xᵢ-x̄)²`
3. **得分计算**：
   - 斜率 < 0（下降趋势）→ 得分 = `-slope × 100`，最高 10 分
   - 斜率 ≥ 0（上升或持平）→ 得分 = 0 分
   - 限制范围：`max(0, min(10, -slope × 100))`

**示例**：
- 时间序列：6 个月的事件数 [100, 95, 90, 85, 80, 75]
- 归一化后：[1.0, 0.95, 0.9, 0.85, 0.8, 0.75]
- 线性回归斜率：-0.05/月（每月下降 5%）
- 趋势得分：`-(-0.05) × 100 = 5.0` 分

**意义**：捕捉整体下降趋势，即使中间有波动也能识别长期衰退。

---

#### 2. 近期状态（40%权重，满分 10 分）

**计算方法**：
1. **窗口选择**：
   - 如果总月数 ≥ 4：窗口大小 = 3 个月
   - 如果总月数 < 4：窗口大小 = 1 个月
2. **计算均值**：
   - 早期均值 = 最早 N 个月的平均值
   - 近期均值 = 最近 N 个月的平均值
3. **变化率计算**：
   - `change = (recent_avg - early_avg) / early_avg`
4. **得分计算**：
   - 变化率 < 0（下降）→ 得分 = `-change × 10`，最高 10 分
   - 变化率 ≥ 0（上升或持平）→ 得分 = 0 分
   - 限制范围：`max(0, min(10, -change × 10))`

**示例**：
- 总月数：12 个月
- 最早 3 月：[100, 95, 90] → 均值 95
- 最近 3 月：[80, 75, 70] → 均值 75
- 变化率：`(75-95)/95 = -21.1%`
- 近期得分：`-(-0.211) × 10 = 2.11` 分

**意义**：关注最近状态，捕捉突发下降或恢复。

---

#### 3. 稳定性（20%权重，满分 5 分）

**计算方法**：
1. **计算月度环比变化率**：
   - 对相邻两个月：`change_i = (value[i] - value[i-1]) / value[i-1]`
   - 得到变化率序列：`[change_1, change_2, ..., change_n-1]`
2. **计算波动率（标准差）**：
   - 均值：`mean_change = Σchange_i / (n-1)`
   - 方差：`variance = Σ(change_i - mean_change)² / (n-1)`
   - 波动率：`volatility = √variance`
3. **得分计算**：
   - 波动率 ≤ 0.3（稳定）→ 得分 = 0 分
   - 波动率 > 0.3（不稳定）→ 得分 = `(volatility - 0.3) × 25`，最高 5 分
   - 限制范围：`max(0, min(5, (volatility - 0.3) × 25))`

**示例 1（稳定下降）**：
- 月度变化率：[-5%, -5%, -5%, -5%, -5%]
- 波动率：0%（标准差为 0）
- 稳定性得分：0 分（无波动惩罚）

**示例 2（波动大）**：
- 月度变化率：[-20%, +10%, -15%, +5%, -10%]
- 波动率：12.2%（标准差）
- 稳定性得分：`(0.122 - 0.3) × 25 = -4.45` → 0 分（未超过阈值）

**示例 3（高度不稳定）**：
- 月度变化率：[-50%, +30%, -40%, +20%, -35%]
- 波动率：35.5%
- 稳定性得分：`(0.355 - 0.3) × 25 = 1.375` 分

**意义**：惩罚高波动性，即使平均值下降不明显，但波动大也说明不稳定。

---

#### 维度总分计算

```
维度总分 = 长期趋势得分 + 近期状态得分 + 稳定性得分
         = (0-10分) + (0-10分) + (0-5分)
         = 0-25分
```

### 四个评估维度详解

#### 1. 活跃度（0-25分）

**数据来源**：每个月的 `total_events`（从图的元数据中获取，表示该月的事件总数）

**计算方法**：
1. 提取时间序列：`[events_month1, events_month2, ..., events_monthN]`
2. 对时间序列应用三层分析：
   - 长期趋势（40%）：线性回归斜率
   - 近期状态（40%）：最近 3 月 vs 最早 3 月
   - 稳定性（20%）：月度变化率波动
3. 得到 0-25 分的得分

**意义**：事件总数下降反映项目活跃度下降，是倦怠的直接信号。

---

#### 2. 贡献者（0-25分）

**数据来源**：每个月的 `unique_actors`（从图的元数据中获取，表示该月的活跃贡献者数量）

**计算方法**：
1. 提取时间序列：`[actors_month1, actors_month2, ..., actors_monthN]`
2. 对时间序列应用三层分析（同上）
3. 得到 0-25 分的得分

**意义**：贡献者数量下降反映社区萎缩，新人减少或老成员流失。

---

#### 3. 核心成员稳定性（0-25分）

**数据来源**：每个月的核心成员 ID 集合（通过核心成员识别算法得到）

**计算方法**：
1. **计算每月留存率**：
   - 以第一个月的核心成员为基准
   - 每月留存率 = `(该月核心成员 ∩ 首月核心成员) / 首月核心成员数`
   - 得到留存率序列：`[1.0, 0.9, 0.8, 0.7, ...]`
2. **转换为流失率**：
   - 流失率 = `1 - 留存率`
   - 得到流失率序列：`[0.0, 0.1, 0.2, 0.3, ...]`
3. **对流失率序列应用三层分析**：
   - 长期趋势：流失率是否持续上升
   - 近期状态：最近流失率 vs 早期流失率
   - 稳定性：流失率波动
4. 得到 0-25 分的得分

**特殊处理**：
- 如果首月没有核心成员，所有月的留存率设为 1.0（流失率为 0）
- 流失率越高，得分越高（倦怠风险越大）

**意义**：核心成员流失是倦怠的强烈信号，反映项目维护能力下降。

---

#### 4. 协作密度（0-25分）

**数据来源**：每个月的 `density`（网络密度）

**密度计算公式**：
```
density = edge_count / (node_count × (node_count - 1))
```
- `edge_count`：图中边的总数
- `node_count`：图中节点的总数
- 对于有向图，最大可能边数为 `node_count × (node_count - 1)`

**计算方法**：
1. 提取时间序列：`[density_month1, density_month2, ..., density_monthN]`
2. 对时间序列应用三层分析（同上）
3. 得到 0-25 分的得分

**意义**：
- 密度高：成员之间协作频繁，社区紧密
- 密度下降：协作减少，可能社区分裂或成员孤立

### 预警信号检测

系统会逐月对比相邻两个月的数据，检测以下预警信号：

#### 1. ACTIVITY_DROP（活跃度下降）

**检测方法**：
1. 对比相邻两个月的事件总数
2. 计算变化率：`变化率 = (本月事件数 - 上月事件数) / 上月事件数`
3. 触发条件：变化率 < -50%（下降超过 50%）
4. 严重程度：
   - `high`：变化率 < -70%（下降超过 70%）
   - `medium`：-70% ≤ 变化率 < -50%

**示例**：
- 上月：1000 事件
- 本月：400 事件
- 变化率：`(400-1000)/1000 = -60%`
- 触发：`medium` 级别预警

---

#### 2. CORE_MEMBER_LOSS（核心成员流失）

**检测方法**：
1. 获取上月和本月的核心成员 ID 集合
2. 计算流失成员：`流失成员 = 上月核心成员 - 本月核心成员`
3. 计算流失率：`流失率 = 流失成员数 / 上月核心成员数`
4. 触发条件：
   - 流失率 ≥ 30%，或
   - 流失绝对数量 ≥ 2 人
5. 严重程度：
   - `high`：流失率 ≥ 50% 或流失 ≥ 3 人
   - `medium`：30% ≤ 流失率 < 50% 且流失 2 人

**示例**：
- 上月核心成员：10 人（ID: [1,2,3,4,5,6,7,8,9,10]）
- 本月核心成员：6 人（ID: [1,2,3,4,5,6]）
- 流失成员：4 人（ID: [7,8,9,10]）
- 流失率：`4/10 = 40%`
- 触发：`medium` 级别预警

---

#### 3. COLLABORATION_DECLINE（协作密度下降）

**检测方法**：
1. 对比相邻两个月的网络密度
2. 计算变化率：`变化率 = (本月密度 - 上月密度) / 上月密度`
3. 触发条件：变化率 < -30%（下降超过 30%）
4. 严重程度：固定为 `medium`

**网络密度计算**：
- `density = 边数 / (节点数 × (节点数 - 1))`
- 密度越高，说明成员之间协作越频繁
- 密度下降可能意味着协作减少、社区分裂

**示例**：
- 上月密度：0.05
- 本月密度：0.03
- 变化率：`(0.03-0.05)/0.05 = -40%`
- 触发：`medium` 级别预警

---

#### 4. CONTRIBUTOR_DROP（贡献者下降）

**检测方法**：
1. 对比相邻两个月的活跃贡献者数量
2. 计算变化率：`变化率 = (本月贡献者数 - 上月贡献者数) / 上月贡献者数`
3. 触发条件：变化率 < -40%（下降超过 40%）
4. 严重程度：固定为 `medium`

**示例**：
- 上月贡献者：50 人
- 本月贡献者：25 人
- 变化率：`(25-50)/50 = -50%`
- 触发：`medium` 级别预警

---

#### 5. SUSTAINED_DECLINE（持续下降）

**检测方法**：
1. 检查最近 3 个月的事件数序列
2. 判断是否连续下降：`events[0] > events[1] > events[2]`
3. 如果连续下降，计算累计下降率：
   - `累计下降率 = (最近1月 - 3个月前) / 3个月前`
4. 触发条件：累计下降率 < -30%（累计下降超过 30%）
5. 严重程度：固定为 `high`

**示例**：
- 3 个月前：1000 事件
- 2 个月前：800 事件（环比 -20%）
- 1 个月前：600 事件（环比 -25%）
- 本月：400 事件（环比 -33%）
- 累计下降率：`(400-1000)/1000 = -60%`
- 触发：`high` 级别预警

**注意**：此预警需要至少 3 个月的数据才能检测。

---

### 综合倦怠评分计算

#### 计算流程

**步骤 1：提取四个维度的时间序列**

1. **活跃度序列**：`[month1.total_events, month2.total_events, ..., monthN.total_events]`
2. **贡献者序列**：`[month1.unique_actors, month2.unique_actors, ..., monthN.unique_actors]`
3. **核心成员流失率序列**：
   - 以首月核心成员为基准
   - 每月流失率 = `1 - (该月核心成员 ∩ 首月核心成员) / 首月核心成员数`
   - 序列：`[month1流失率, month2流失率, ..., monthN流失率]`
4. **协作密度序列**：`[month1.density, month2.density, ..., monthN.density]`

**步骤 2：对每个维度应用三层分析**

对每个时间序列分别计算：
- 长期趋势得分（0-10分）
- 近期状态得分（0-10分）
- 稳定性得分（0-5分）

得到每个维度的总分（0-25分）。

**步骤 3：综合评分**

```
综合倦怠评分 = 活跃度得分 + 贡献者得分 + 核心成员稳定性得分 + 协作密度得分
            = (0-25) + (0-25) + (0-25) + (0-25)
            = 0-100分
```

#### 评分示例

假设某项目经过 12 个月的分析，四个维度得分如下：

| 维度 | 长期趋势 | 近期状态 | 稳定性 | 维度总分 |
|-----|---------|---------|--------|---------|
| **活跃度** | 8.5分 | 7.2分 | 4.3分 | **20.0分** |
| **贡献者** | 7.8分 | 6.5分 | 3.4分 | **17.7分** |
| **核心成员** | 1.2分 | 2.1分 | 1.7分 | **5.0分** |
| **协作密度** | 4.5分 | 3.8分 | 2.0分 | **10.3分** |
| **总分** | | | | **53.0分** |

**解读**：
- **活跃度（20.0分）**：事件总数明显下降，长期和近期都有下降趋势
- **贡献者（17.7分）**：活跃人数下降，但波动相对较小
- **核心成员（5.0分）**：核心成员相对稳定，流失率较低
- **协作密度（10.3分）**：网络密度下降，但下降幅度中等
- **总体评价**：中等风险（53.0分），主要问题是活跃度和贡献者下降

### 风险等级划分

| 分数区间 | 等级 | 含义 | 建议 |
|---------|------|------|------|
| ≥60 | 🔴 high | 高倦怠风险，需要关注 | 立即调查原因，考虑干预措施 |
| 40-59 | 🟠 medium | 中等风险，有下降趋势 | 持续监控，准备应对方案 |
| 20-39 | 🟡 low | 低风险，基本健康 | 正常监控即可 |
| <20 | 🟢 healthy | 健康，无明显问题 | 保持现状 |

---

## 指标计算详解

### 基础网络指标

**节点数（node_count）**：
- 直接统计图中的节点总数
- 使用 NetworkX 的 `graph.number_of_nodes()` 方法

**边数（edge_count）**：
- 直接统计图中的边总数
- 使用 NetworkX 的 `graph.number_of_edges()` 方法

**网络密度（density）**：
- 计算公式：`density = edge_count / (node_count × (node_count - 1))`
- 对于有向图，最大可能边数为 `node_count × (node_count - 1)`
- 密度范围：0（无连接）到 1（完全连接）

---

### 度中心性统计

**度数计算**：
- 对每个节点：`度数 = 入度 + 出度`
- 入度：指向该节点的边数
- 出度：从该节点发出的边数

**统计量计算**：
- **平均度数**：`degree_mean = Σ所有节点度数 / 节点数`
- **最大度数**：`degree_max = max(所有节点度数)`
- **度数标准差**：
  1. 计算均值：`μ = degree_mean`
  2. 计算方差：`variance = Σ(度数ᵢ - μ)² / 节点数`
  3. 计算标准差：`degree_std = √variance`

**标准差的意义**：
- 标准差大：度数分布不均匀，存在"头部效应"（少数人贡献了大部分交互）
- 标准差小：度数分布均匀，贡献相对分散

---

### 线性回归斜率（长期趋势计算）

**计算方法**（最小二乘法）：
1. **准备数据**：
   - x 轴：月份索引 `[0, 1, 2, ..., n-1]`
   - y 轴：归一化后的数值序列（除以第一个非零值）
2. **计算均值**：
   - `x_mean = (n - 1) / 2`
   - `y_mean = Σyᵢ / n`
3. **计算斜率**：
   - 分子：`Σ(i - x_mean) × (yᵢ - y_mean)`
   - 分母：`Σ(i - x_mean)²`
   - 斜率：`slope = 分子 / 分母`
4. **斜率含义**：
   - 斜率 < 0：下降趋势（值越小，下降越快）
   - 斜率 = 0：稳定
   - 斜率 > 0：上升趋势

**示例**：
- 时间序列：[100, 95, 90, 85, 80, 75]（6 个月）
- 归一化后：[1.0, 0.95, 0.9, 0.85, 0.8, 0.75]
- x = [0, 1, 2, 3, 4, 5]
- x_mean = 2.5, y_mean = 0.875
- 斜率 ≈ -0.05/月（每月下降 5%）

---

### 波动率计算（稳定性计算）

**计算方法**：
1. **计算月度环比变化率**：
   - 对相邻两个月：`变化率ᵢ = (值[i] - 值[i-1]) / 值[i-1]`
   - 得到变化率序列：`[变化率₁, 变化率₂, ..., 变化率ₙ₋₁]`
2. **计算标准差**：
   - 均值：`mean_change = Σ变化率ᵢ / (n-1)`
   - 方差：`variance = Σ(变化率ᵢ - mean_change)² / (n-1)`
   - 波动率：`volatility = √variance`
3. **波动率含义**：
   - 波动率大：月度变化不稳定，忽高忽低
   - 波动率小：月度变化稳定，趋势平滑

**示例 1（稳定下降）**：
- 月度值：[100, 95, 90, 85, 80]
- 变化率：[-5%, -5.26%, -5.56%, -5.88%]
- 波动率：≈ 0.4%（非常稳定）

**示例 2（波动大）**：
- 月度值：[100, 80, 100, 70, 90]
- 变化率：[-20%, +25%, -30%, +28.6%]
- 波动率：≈ 25.8%（波动很大）

---

## 项目结构

```
oss_graph_construction/
├── src/
│   ├── analysis/                    # 分析模块
│   │   ├── monthly_graph_builder.py # 月度图构建
│   │   ├── burnout_analyzer.py      # 倦怠分析
│   │   └── detailed_report.py       # 详细报告生成
│   ├── data_collection/             # 数据采集
│   │   ├── gharchive_collector.py   # GitHub Archive 下载器
│   │   └── representative_projects.py # 代表性项目列表
│   ├── models/                      # 数据模型
│   ├── services/                    # 核心服务
│   │   └── temporal_semantic_graph/ # 图构建服务
│   ├── cli/                         # 命令行接口
│   └── utils/                       # 工具函数
├── data/
│   └── filtered/                    # 过滤后的事件数据
├── output/
│   ├── monthly-graphs/              # 月度图文件
│   │   └── {owner}-{repo}/
│   │       ├── actor-actor/
│   │       ├── actor-repo/
│   │       └── actor-discussion/
│   └── burnout-analysis/            # 分析结果
│       ├── summary.json             # 评分排名
│       ├── all_alerts.json          # 预警列表
│       ├── full_analysis.json       # 完整分析数据
│       └── detailed_report.txt      # 可读报告
├── scripts/
│   ├── collect_data.sh              # 数据采集脚本
│   └── analyze_burnout.sh           # 分析运行脚本
└── requirements.txt
```

---

## 命令行参考

### 数据采集

```bash
python -m src.data_collection.gharchive_collector \
  --start-date 2023-01-01 \
  --end-date 2025-12-31 \
  --sample-mode monthly \      # daily/weekly/monthly
  --output-dir data/filtered \
  --resume                     # 断点续传
```

### 月度图构建

```bash
python -m src.analysis.monthly_graph_builder \
  --data-dir data/filtered \
  --output-dir output/monthly-graphs \
  --workers 4                  # 并行进程数
```

### 倦怠分析

```bash
python -m src.analysis.burnout_analyzer \
  --graphs-dir output/monthly-graphs \
  --output-dir output/burnout-analysis
```

### 详细报告

```bash
# 查看前 N 个高风险项目
python -m src.analysis.detailed_report --top 10

# 查看指定项目
python -m src.analysis.detailed_report --repo "kubernetes/kubernetes,facebook/react"

# 只看高风险项目（评分 ≥ 60）
python -m src.analysis.detailed_report --min-score 60

# 指定输出文件
python -m src.analysis.detailed_report --output my_report.txt
```

---

## 输出示例

### 详细报告片段

```
================================================================================
📊 项目: kubernetes/kubernetes
================================================================================

🎯 综合倦怠评分: 35.42 / 100
   风险等级: 🟡 低风险
   分析周期: 2023-01 to 2025-12 (36 个月)

--------------------------------------------------------------------------------
📈 各因子详细分析（三层架构：长期趋势40% + 近期状态40% + 稳定性20%）
--------------------------------------------------------------------------------

【1. 活跃度】(0-25分)
   📊 数据概览:
      首月: 1250.00 事件  →  末月: 890.00 事件
   📉 长期趋势 (40%权重):
      线性回归斜率: -2.15%/月
      ⚠️ 每月平均下降 2.2%
      → 趋势得分: 2.15
   📅 近期状态 (40%权重):
      早期3月均值: 1180.33  →  近期3月均值: 920.67
      变化率: -22.0%
      → 近期得分: 2.20
   📊 稳定性 (20%权重):
      月度波动率: 18.5%
      ✅ 波动可控 (≤30%)
      → 稳定性扣分: 0.00
   ➡️ 维度总分: 4.35 / 25
```

---

## 技术栈

- **Python 3.8+**
- **NetworkX**: 图构建与算法
- **tqdm**: 进度显示
- **multiprocessing**: 并行处理

## 许可证

MIT License
